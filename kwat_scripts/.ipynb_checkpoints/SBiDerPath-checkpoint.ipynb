{
 "metadata": {
  "name": "",
  "signature": "sha256:8d7d9694742efc7cb8cf177c1f6fb6fcd12c9f29f3220c03d0ac1a9006c6d2f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''finds the last index of an element in a sequence'''\n",
      "def rindex(sequence, element):\n",
      "    for i, e in enumerate(reversed(sequence)):\n",
      "        if element == e:\n",
      "            return len(sequence) - 1 - i\n",
      "    else:\n",
      "            raise ValueError(\"rindex(sequence, element): element not in the sequence\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''removes the outer most parentheses \"()\" and returns the token afte the \")\"'''\n",
      "def parentheses(sequence):\n",
      "    print \"parentheses(sequence): sequence: \", sequence\n",
      "    first_opener_idx_assigned = False\n",
      "    started = False\n",
      "    counter = 0\n",
      "    for idx, e in enumerate(sequence):\n",
      "        if e == '(':\n",
      "            if started == False:\n",
      "                started = True\n",
      "            counter = counter + 1\n",
      "        elif e == ')':\n",
      "            if started == False:\n",
      "                raise ValueError(\"parentheses(sequence): ')' without '('\")\n",
      "            counter = counter - 1\n",
      "        if started == True:\n",
      "            if first_opener_idx_assigned == False:\n",
      "                first_opener_idx = idx\n",
      "                first_opener_idx_assigned = True\n",
      "            if counter == 0:\n",
      "                sequence.pop(idx)\n",
      "                if idx < len(sequence):\n",
      "                    element_after_last_closer = sequence[idx]\n",
      "                else:\n",
      "                    element_after_last_closer = None\n",
      "                sequence.pop(first_opener_idx)\n",
      "                return element_after_last_closer\n",
      "    print \"parentheses(sequence): no parentehses in the sequence\"\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''splits a sequence by a given element and stores the elements\n",
      "before and after the element into a dictionary'''\n",
      "def split_by(sequence, element):\n",
      "    element_index = sequence.index(element)\n",
      "    sequence_before_element = sequence[:element_index:1]\n",
      "    sequence_after_element = sequence[element_index + 1::1]\n",
      "    return {0: sequence_before_element, 1: sequence_after_element}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''class: UISA (User Input Syntax Analyzer)'''\n",
      "class UISA:\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''constructor'''\n",
      "    def __init__(self, tokens):\n",
      "        print \"UISA.__init__(self, tokens): tokens: \", tokens\n",
      "        \"beigns syntax-analyzer-semantic-evaluator recursion\"\n",
      "        print \"RETURN:\\n\", self.g0(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''g0:= g1 > g1'''\n",
      "    def g0(self, tokens):\n",
      "        print \"UISA.g(self, tokens): tokens: \", tokens\n",
      "        if '>' not in tokens:\n",
      "            raise ValueError(\"g(self, tokens): no output\")\n",
      "        else:\n",
      "            input_output_dictionary = split_by(tokens, '>')\n",
      "        return self.gOutput(self.g1(input_output_dictionary[0]), self.g1(input_output_dictionary[1]))\n",
      "        \n",
      "    \n",
      "    \n",
      "    '''g1:= g2 or g1 | g2 and g1 | g2'''\n",
      "    def g1(self, tokens):        \n",
      "        print \"UISA.g1(self, tokens): tokens: \", tokens\n",
      "        if len(tokens) > 1 and tokens[1] == 'or':\n",
      "            \"g2 or g1\"\n",
      "            print \"UISA.g0(self, tokens): detected 'or'\"\n",
      "            \"splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\"\n",
      "            or_dictionary = split_by(tokens, 'or')\n",
      "            return self.gOr(self.g2(or_dictionary.get(0)), self.g1(or_dictionary.get(1)))\n",
      "        elif len(tokens) > 1 and tokens[1] == 'and':\n",
      "            \"g2 and g1\"\n",
      "            print \"UISA.g1(self, tokens): detected 'and'\"\n",
      "            \"splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\"\n",
      "            and_dictionary = split_by(tokens, 'and')\n",
      "            return self.gAnd(self.g2(and_dictionary.get(0)), self.g1(and_dictionary.get(1)))            \n",
      "        else:\n",
      "            \"g2\"\n",
      "            \"delegates to g2\"\n",
      "            return self.g2(tokens)\n",
      "        \n",
      "        \n",
      "        \n",
      "    '''g2:= (g1) or g1 | (g1) and g1 | (g1) | interactor''' \n",
      "    def g2(self, tokens):\n",
      "        print \"UISA.g2(self, tokens): tokens: \", tokens\n",
      "        if tokens[0] == \"(\":\n",
      "            \"(g1) or g1 | (g1) and g1| (g1)\"\n",
      "            print \"UISA.g2(self, tokens): detected '('\"\n",
      "            \"token after the last occuring ')'\"\n",
      "            token_after_last_closer = parentheses(tokens)\n",
      "            if token_after_last_closer == 'or':    \n",
      "                \"splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\"\n",
      "                or_dictionary = split_by(tokens, 'or')\n",
      "                return self.gOr(self.g1(or_dictionary.get(0)), self.g1(or_dictionary.get(1)))\n",
      "            elif token_after_last_closer == 'and':\n",
      "                \"splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\"\n",
      "                and_dictionary = split_by(tokens, 'and')\n",
      "                return self.gAnd(self.g1(and_dictionary.get(0)), self.g1(and_dictionary.get(1)))\n",
      "            else:\n",
      "                \"delegates to interactor\"\n",
      "                return self.g1(tokens)\n",
      "        else:\n",
      "            \"interactor\"\n",
      "            \"delegates to interactor\"\n",
      "            return self.interactor(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''interactor:= lacI | cI | ... | etc.'''\n",
      "    def interactor(self, tokens):\n",
      "        print \"UISA.interactor(self, tokens): tokens: \", tokens\n",
      "        \"returns an interactor\"\n",
      "        return tokens\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''>'''\n",
      "    def gOutput(self, tokens1, tokens2):\n",
      "        toBeReturned = []\n",
      "        for token1 in tokens1:\n",
      "            for token2 in tokens2:\n",
      "                toBeReturned.append(('[' + token1 + '] ---> [' + token2 + ']'))\n",
      "        return toBeReturned\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''Or'''\n",
      "    def gOr(self, tokens1, tokens2):\n",
      "        return tokens1 + tokens2\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''And'''\n",
      "    def gAnd(self, tokens1, tokens2):\n",
      "        toBeReturned = []\n",
      "        for token1 in tokens1:\n",
      "            for token2 in tokens2:\n",
      "                toBeReturned.append(token1 + (\" and \" + token2))\n",
      "        return toBeReturned"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''main'''\n",
      "def main1(user_input):\n",
      "    user_input_token= user_input.split()\n",
      "    uisa = UISA(user_input_token)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#accepts multiple outputs, but not multiple inputs. The parser/convergence algorithms cover cases of multiple inputs.\n",
      "def traversal(graph, graph2, start, goal):\n",
      "    #graph is inputTrans, graph2 speciesTrans, both of which are generated by Joaquin. start is the initial input from \n",
      "    #Kwat's code, goal is the desired output\n",
      "    \n",
      "    #queue is a list containing tuples of paths that have not yet been fully explored\n",
      "    queue=[([],[start])]\n",
      "    \n",
      "    #paths are returned at the end of the traversal. List of lists containing all possible paths to goal\n",
      "    paths=[]\n",
      "    \n",
      "    #visited is returned at the end of the traversal. List of lists containing all explored transitions. The indecies of paths\n",
      "    #and visited match, for instance, the path specified by paths[1] is produced by exploring the transitions contained in \n",
      "    #visited[1]\n",
      "    visited=[]\n",
      "    \n",
      "    #number of times the while loop runs, used for error checking\n",
      "    numRuns=0\n",
      "    \n",
      "    #while there are still tuples representing incomplete paths in the queue, continue to run checker\n",
      "    while queue!=[]:\n",
      "        numRuns+=1\n",
      "        \n",
      "        #expands the queue by one transition\n",
      "        queue,paths,visited,numRuns=checker(graph,graph2,start,goal,queue,paths,visited,numRuns)\n",
      "        \n",
      "    return paths,visited,numRuns\n",
      "\n",
      "def checker(graph,graph2,start,goal,queue,paths,visited,numRuns):\n",
      "    #tempVisited is a local variable that represents the nodes visited for the path in the current queue selection\n",
      "    #pathOrig is the list of species produced by the transitions present in the current queue\n",
      "    (tempVisited, pathOrig) = queue.pop(0)\n",
      "    \n",
      "    #initiates the input list with the start values\n",
      "    inputs=[start]\n",
      "    \n",
      "    #expands the list of inputs by appending all species produced by each transition already explored. Duplicates are possible\n",
      "    for next in tempVisited:\n",
      "        temp=graph2[next]\n",
      "        for species in temp:\n",
      "            inputs.append(species)\n",
      "            \n",
      "    #explores each transition that is not already explored\n",
      "    for next in set(graph.keys())-set(tempVisited):\n",
      "        \n",
      "        #temporary path list for eacch transition explored in the loop\n",
      "        path=[]\n",
      "        \n",
      "        #adds all species from the original path specified by the queue. This prevents the original path from being\n",
      "        #overwritten by the set math\n",
      "        for species in pathOrig:\n",
      "            path.append(species)\n",
      "            \n",
      "        #vis is a temporary visited list that prevents overwritting of tempVisited or visited\n",
      "        vis=[]\n",
      "        for transition in tempVisited:\n",
      "            vis.append(transition)\n",
      "            \n",
      "        #determines if the currently selected transition specified by 'next' is satisfied by the current list of inputs\n",
      "        selection=graph[next]\n",
      "        a=selection.issubset(set(inputs))\n",
      "        if a==True:\n",
      "            vis=vis+[next]\n",
      "            \n",
      "            #removes the redundant entries from the path\n",
      "            path=removeRedundant(path,graph2[next])\n",
      "            \n",
      "            #if the desired output is contained within the current path, append the path without appending to queue\n",
      "            if set(goal).issubset(set(path)):\n",
      "                paths.append(path)\n",
      "                visited.append(vis)\n",
      "                \n",
      "            #if the desired output is not contained, but the selected transition is satisfied, append the new path and\n",
      "            #visited list to queue for further exploration\n",
      "            else:\n",
      "                queue.append((vis,path))\n",
      "    \n",
      "    return queue,paths,visited,numRuns\n",
      "\n",
      "#method for removing redundant entries\n",
      "def removeRedundant(lst1,lst2):\n",
      "    path=lst1\n",
      "    for i in lst2:\n",
      "        if i not in lst1:\n",
      "            path.append(i)\n",
      "    return path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "([], [], 73)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inputTrans = {\n",
      "#input transition ID: [intermediate(s) required to trigger the transition]\n",
      "'t0':['A'],\n",
      "'t1':['B'],\n",
      "'t2':['C'],\n",
      "'t3':['D'],\n",
      "'t4':['E']\n",
      "}\n",
      "\n",
      "outputTrans = {\n",
      "#output transition ID: set( [intermediate(s) produced by the transition] )\n",
      "'t0':set( ['B'] ),\n",
      "'t1':set( ['C'] ),\n",
      "'t2':set( ['D'] ),\n",
      "'t3':set( ['E'] ),\n",
      "'t4':set( ['X'] )\n",
      "}\n",
      "\n",
      "user_input = \"A > X\"\n",
      "\n",
      "print traversal(inputTrans, outputTrans, 'A', 'X')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}