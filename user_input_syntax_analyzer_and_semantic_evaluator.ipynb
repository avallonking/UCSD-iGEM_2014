{
 "metadata": {
  "name": "",
  "signature": "sha256:a53da9a655f47d9f4829744e4e06bc0f8ebc8dcc106cfb1cbaab78f27eb5f328"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''user input test cases'''\n",
      "user_input_0 = \"> X\"\n",
      "user_input_1 = \"A > X\"\n",
      "user_input_2 = \"( A ) > X\"\n",
      "\n",
      "user_input_3 = \"A or B > X\"\n",
      "user_input_4 = \"( A or B ) > X\"\n",
      "user_input_5 = \"( A ) or ( B ) > X\"\n",
      "user_input_6 = \"( ( A ) or ( B ) ) > X\"\n",
      "\n",
      "user_input_7 = \"A and B > X\"\n",
      "user_input_8 = \"( A and B ) > X\"\n",
      "user_input_9 = \"( A ) and ( B ) > X\"\n",
      "user_input_10 = \"( ( A ) and ( B ) ) > X\"\n",
      "\n",
      "user_input_11 = \"A or B or C > X\"\n",
      "user_input_12 = \"( A or B or C ) > X\"\n",
      "user_input_13 = \"( A or B ) or C > X\"\n",
      "user_input_14 = \"A or ( B or C ) > X\"\n",
      "user_input_15 = \"( ( A or B ) or C ) > X\"\n",
      "user_input_16 = \"( A or ( B or C ) ) > X\"\n",
      "\n",
      "user_input_17 = \"A and B and C > X\"\n",
      "user_input_18 = \"( A and B and C ) > X\"\n",
      "user_input_19 = \"( A and B ) and C > X\"\n",
      "user_input_20 = \"A and ( B and C ) > X\"\n",
      "user_input_21 = \"( ( A and B ) and C ) > X\"\n",
      "user_input_22 = \"( A and ( B and C ) ) > X\"\n",
      "\n",
      "user_input_23 = \") > X\"\n",
      "\n",
      "for i in range(0, 24):\n",
      "    exec(\"tokens_%d = user_input_%d.split()\" % (i,i))\n",
      "    '''exec(\"print tokens_%d\" % i)'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''finds the last index of an element in a sequence'''\n",
      "def rindex(sequence, element):\n",
      "    for i, e in enumerate(reversed(sequence)):\n",
      "        if element == e:\n",
      "            return len(sequence) - 1 - i\n",
      "    else:\n",
      "            raise ValueError(\"rindex(sequence, element): element not in the sequence\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''removes the outer most parentheses \"()\" and returns the token afte the \")\"'''\n",
      "def parentheses(sequence):\n",
      "    print \"parentheses(sequence): sequence: \", sequence\n",
      "    first_opener_idx_assigned = False\n",
      "    started = False\n",
      "    counter = 0\n",
      "    for idx, e in enumerate(sequence):\n",
      "        if e == '(':\n",
      "            if started == False:\n",
      "                started = True\n",
      "            counter = counter + 1\n",
      "        elif e == ')':\n",
      "            if started == False:\n",
      "                raise ValueError(\"parentheses(sequence): ')' without '('\")\n",
      "            counter = counter - 1\n",
      "        if started == True:\n",
      "            if first_opener_idx_assigned == False:\n",
      "                first_opener_idx = idx\n",
      "                first_opener_idx_assigned = True\n",
      "                '''print \"parentheses(sequence): first_opener_idx: \", first_opener_idx'''\n",
      "            if counter == 0:\n",
      "                '''print \"parentheses(sequence): pop: \", sequence[idx], \"from index: \", idx'''\n",
      "                sequence.pop(idx)\n",
      "                if idx < len(sequence):\n",
      "                    element_after_last_closer = sequence[idx]\n",
      "                else:\n",
      "                    element_after_last_closer = None\n",
      "                '''print \"parentheses(sequence): pop: \", sequence[first_opener_idx], \"from index: \", first_opener_idx'''\n",
      "                sequence.pop(first_opener_idx)\n",
      "                '''print \"parentheses(sequence): final sequence: \", sequence'''\n",
      "                return element_after_last_closer\n",
      "    print \"parentheses(sequence): no parentehses in the sequence\"\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''splits a sequence by a given element and stores the elements\n",
      "before and after the element into a dictionary'''\n",
      "def split_by(self, sequence, element):\n",
      "    element_index = sequence.index(element)\n",
      "    sequence_before_element = sequence[:element_index:1]\n",
      "    sequence_after_element = sequence[element_index + 1::1]\n",
      "    '''print \"split_by(sequence, element): before element: \", sequence_before_element\n",
      "    print \"split_by(sequence, element): after element: \", sequence_after_element'''\n",
      "    return {0: sequence_before_element, 1: sequence_after_element}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''class: UISA (User Input Syntax Analyzer)'''\n",
      "class UISA:\n",
      "    '''constructor'''\n",
      "    def __init__(self, tokens):\n",
      "        print \"UISA.__init__(self, tokens): tokens: \", tokens\n",
      "        \"beigns syntax-analyzer-semantic-evaluator recursion\"\n",
      "        self.g0(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''g0:= g2 or g0 | g1'''    \n",
      "    def g0(self, tokens):\n",
      "        print \"UISA.g0(self, tokens): tokens: \", tokens\n",
      "        if len(tokens) > 1 and tokens[1] == 'or':\n",
      "            \"g2 or g0\"\n",
      "            print \"UISA.g0(self, tokens): detected 'or'\"\n",
      "            \"splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\"\n",
      "            or_dictionary = self.split_by(tokens, 'or')\n",
      "            \"returns a GOr object with the tokens\"\n",
      "            gor = GOr(self.g2(or_dictionary.get(0)), self.g0(or_dictionary.get(1)))\n",
      "            return gor\n",
      "        else:\n",
      "            \"g1\"\n",
      "            \"delegates to g1\"\n",
      "            return self.g1(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''g1:= g2 and g0 | g2'''\n",
      "    def g1(self, tokens):\n",
      "        print \"UISA.g0(self, tokens): tokens: \", tokens\n",
      "        if len(tokens) > 1 and tokens[1] == 'and':\n",
      "            \"g2 and g0\"\n",
      "            print \"UISA.g1(self, tokens): detected 'and'\"\n",
      "            \"splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\"\n",
      "            and_dictionary = self.split_by(tokens, 'and')\n",
      "            \"returns a GAnd object with the tokens\"\n",
      "            gand = GAnd(and_dictionary.get(0), and_dictionary.get(0))\n",
      "            return gand\n",
      "        else:\n",
      "            \"g2\"\n",
      "            \"delegates to g2\"\n",
      "            return self.g2(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''g2:= (g0) or | (g0) and | (g0) | interactor''' \n",
      "    def g2(self, tokens):\n",
      "        print \"UISA.g2(self, tokens): tokens: \", tokens\n",
      "        if tks[0] == \"(\":\n",
      "            \"(g0) or | (g0) and | (g0)\"\n",
      "            print \"UISA.g2(self, tokens): detected 'or'\"\n",
      "            \"token after the last occuring ')'\"\n",
      "            token_after_last_closer = parentheses(tokens)\n",
      "            print \"UISA.g2(self, tokens): token_after_last_closer: \", token_after_last_closer\n",
      "            if token_after_last_closer == 'or':    \n",
      "                \"splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\"\n",
      "                or_dictionary = self.split_by(tokens, 'or')\n",
      "                \"returns a GOr object with the tokens\"\n",
      "                gor = GOr(self.g2(or_dictionary.get(0)), self.g0(or_dictionary.get(1)))\n",
      "                return gor\n",
      "            elif token_after_last_closer == 'and':\n",
      "                \"splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\"\n",
      "                and_dictionary = self.split_by(tokens, 'and')\n",
      "                \"returns a GAnd object with the tokens\"\n",
      "                gand = GAnd(and_dictionary.get(0), and_dictionary.get(1))\n",
      "                return gand\n",
      "            else:\n",
      "                \"delegates to interactor\"\n",
      "                return self.g0(tokens)\n",
      "        else:\n",
      "            \"interactor\"\n",
      "            \"delegates to interactor\"\n",
      "            return self.interactor(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''interactor:= lacI | cI | ... | etc.'''\n",
      "    def interactor(self, tokens):\n",
      "        print \"UISA.interactor(self, tokens): tokens: \", tokens\n",
      "        \"returns an interactor\"\n",
      "        return \"X\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''class: GOr (Grammar Or)'''\n",
      "class GOr:\n",
      "    '''constructor'''\n",
      "    def __init__(self, tokens_before, tokens_after):\n",
      "        '''self.tokens_before = tokens_before\n",
      "        self.tokens_after = tokens_after\n",
      "        print \"GOr.__init__(self, tokens_before, tokens_after): tokens_before: \", tokens_before, \"tokens_after: \", tokens_after'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''class: Gand (Grammar And)'''\n",
      "class GAnd:\n",
      "    '''constructor'''\n",
      "    def __init__(self, tokens_before, tokens_after):\n",
      "        '''self.tokens_before = tokens_before\n",
      "        self.tokens_after = tokens_after\n",
      "        print \"GAnd.__init__(self, tokens_before, tokens_after): tokens_before: \", tokens_before, \"tokens_after: \", tokens_after'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''main'''\n",
      "def main(user_input):\n",
      "    if '>' in user_input:\n",
      "        suffix = user_input[user_input.index('>')::1]\n",
      "    else:\n",
      "        raise ValueError(\"main(user_input): missing output '> ...'\")\n",
      "        return\n",
      "    tokens = user_input[:user_input.index('>'):1]\n",
      "    uisa = UISA(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    }
   ],
   "metadata": {}
  }
 ]
}