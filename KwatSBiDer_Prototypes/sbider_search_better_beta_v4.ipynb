{
 "metadata": {
  "name": "",
  "signature": "sha256:a9d2fb00c283b54f1f773cc5511e50225366c3bd778f7694ae6fb9df15e8b5b6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import networkx as nx\n",
      "import itertools\n",
      "import collections\n",
      "import weakref"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_duplicates_within_list(seq):\n",
      "    seen = set()\n",
      "    seen_add = seen.add\n",
      "    return [ x for x in seq if not (x in seen or seen_add(x))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_is_type(lst, typ):\n",
      "    \"\"\"\n",
      "    Check if all elements in a list is the same specified type.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(lst) != list:\n",
      "        raise TypeError(\"list_is_type(lst, typ): lst is not a list\")\n",
      "    elif len(lst) <= 0:\n",
      "        raise ValueError(\"list_is_type(lst, typ): lst is empty\")\n",
      "    return all(isinstance(x,typ) for x in lst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_duplicated_lists_within_a_list_of_lists(list_of_lists):\n",
      "    \"\"\"\n",
      "    Removes any duplicated lists, which contain same elements in same order, within a list of lists.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        list_of_lists.sort()\n",
      "        trimmed = list(list_of_lists for list_of_lists,_ in itertools.groupby(list_of_lists))\n",
      "        return trimmed\n",
      "    else:\n",
      "        raise TypeError(\"remove_duplicated_lists_within_a_list_of_lists(list_of_lists): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uniquely_merge_list_of_lists(list_of_lists):\n",
      "    \"\"\"\n",
      "    Merge unique elements from lists within a list.\n",
      "    \n",
      "    Argument:\n",
      "        list_of_lists - a list that contains multiple lists.\n",
      "    \n",
      "    Return:\n",
      "        a new list that contains unique elements from all lists within a list of lists.\n",
      "    \"\"\"   \n",
      "    \n",
      "    if type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        remove_duplicated_lists_within_a_list_of_lists(list_of_lists)\n",
      "        merged_list = list(list_of_lists[0])\n",
      "        for a_list in list_of_lists[1::]:\n",
      "                for e in a_list:\n",
      "                    if e not in merged_list:\n",
      "                        merged_list.append(e)\n",
      "        return merged_list\n",
      "    else:\n",
      "        ###print list_of_lists\n",
      "        \n",
      "        return list(list_of_lists)\n",
      "        raise TypeError(\"uniquely_merge_list_of_lists(list_of_lists): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uniquely_merge_multi_dimentional_list_of_lists(multi_dimentional_list_of_lists):\n",
      "    print \"uniquely_merge_multi_dimentional_list_of_lists(): multi_dimentional_list_of_lists: \", multi_dimentional_list_of_lists \n",
      "    final_merged_list = uniquely_merge_list_of_lists(multi_dimentional_list_of_lists)\n",
      "    if type(final_merged_list) == list and len(final_merged_list) > 0 and list_is_type(final_merged_list, list) == True:\n",
      "        return uniquely_merge_multi_dimentional_list_of_lists(final_merged_list)\n",
      "    else:\n",
      "        return final_merged_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def elements_match(list_of_lists, lst):\n",
      "    return set(lst).issubset(uniquely_merge_list_of_lists(list_of_lists))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_matching_list(list_of_lists, lst):\n",
      "    \"\"\"\n",
      "    Get any list that match a specified list.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(lst) != list:\n",
      "        raise TypeError(\"get_matching_list(list_of_lists, lst): lst is not a list object\")    \n",
      "    elif type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        matching_list = []\n",
      "        for a_list in list_of_lists:\n",
      "            if all([x in lst for x in a_list]) == True:\n",
      "                matching_list.append(a_list)\n",
      "        return matching_list\n",
      "    else:\n",
      "        raise TypeError(\"get_matching_list(list_of_lists, lst): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def match_any_list(list_of_lists, lst):\n",
      "    \"\"\"\n",
      "    Check if a list matches any of lists within a list.\n",
      "    \"\"\"\n",
      "            \n",
      "    if get_matching_list(list_of_lists, lst) == []:\n",
      "        return False\n",
      "    else:\n",
      "        return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sbider_path(input_dictionary,\n",
      "                    output_dictionary,\n",
      "                    input_species_list,\n",
      "                    output_species_list):\n",
      "    \n",
      "    path_queue = [ ([],input_species_list) ]\n",
      "    final_operon_path_list = []\n",
      "    final_species_path_list = []\n",
      "    memory_species_queue = [input_species_list]\n",
      "    memory_species = []\n",
      "    memory_operon = []\n",
      "    memory_path_queue = []\n",
      "    operon_path, spieces_path = sbider_path(input_dictionary,\n",
      "                                            output_dictionary,\n",
      "                                            input_species_list,\n",
      "                                            output_species_list,\n",
      "                                            path_queue,\n",
      "                                            final_operon_path_list,\n",
      "                                            final_species_path_list,\n",
      "                                            memory_operon,\n",
      "                                            memory_species,\n",
      "                                            memory_species_queue,\n",
      "                                            memory_path_queue)\n",
      "    return operon_path, spieces_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sbider_path(input_dictionary,\n",
      "                output_dictionary,\n",
      "                input_species_list,\n",
      "                output_species_list,\n",
      "                path_queue,\n",
      "                final_operon_path_list,\n",
      "                final_species_path_list,\n",
      "                memory_operon,\n",
      "                memory_species,\n",
      "                memory_species_queue,\n",
      "                memory_path_queue):\n",
      "    \"\"\"Construct path\"\"\"\n",
      "    \n",
      "    ###print \"@\" * 99\n",
      "    ###print \"********* path_queue:\", path_queue, len(path_queue)\n",
      "    ###print \"********* final_operon_path_list:\", final_operon_path_list\n",
      "    ###print \"********* final_species_path_list:\", final_species_path_list\n",
      "    ###print \"********* memory_operon:\", memory_operon\n",
      "    ###print \"********* memory_species:\", memory_species\n",
      "    ###print \"********* memory_species_queue:\", memory_species_queue\n",
      "    ###print \"#\" * 99\n",
      "        \n",
      "    while len(path_queue) != 0:\n",
      "        ###print \"\\t ######### <per pop> path_queue:\", path_queue, len(path_queue)\n",
      "        ###print \"\\t ######### <per pop> memory_operon:\", memory_operon \n",
      "        ###print \"\\t ######### <per pop> memory_species:\", memory_species\n",
      "        ###print \"\\t ######### <per pop> memory_species_queue:\", memory_species_queue, len(memory_species_queue)\n",
      "        \n",
      "        (previously_visited_operon_list, just_previously_produced_species_list) = path_queue.pop(0)\n",
      "        previously_visited_species_list = memory_species_queue.pop(0)\n",
      "        \n",
      "        ###print \"\\n\\t searching for operons that can be activated by:\", just_previously_produced_species_list\n",
      "        ###print \"\\t operons yet to be visited:\", set(input_dictionary.keys()) - set(previously_visited_operon_list)\n",
      "        for an_operon in set(input_dictionary.keys()) - set(previously_visited_operon_list):\n",
      "            \n",
      "            activation_requirement = input_dictionary[an_operon]\n",
      "            \n",
      "            ###print \"\\n\\t\\t potential operon & its input species:\", an_operon, \" & \", activation_requirement\n",
      "            ###print \"\\t\\t (ACTIVATE?)Does species\", just_previously_produced_species_list, \"match an_operon's input species:\", activation_requirement,\"?\"\n",
      "            if match_any_list(activation_requirement, just_previously_produced_species_list) == True:\n",
      "\n",
      "                ###print \"\\n\\t\\t\\t !!!ACTIVATION!!!\"\n",
      "                ###print \"\\t\\t\\t <OPERON>\"\n",
      "                ###print \"\\t\\t\\t (<before>) previously_visited_operon_list:\", previously_visited_operon_list\n",
      "                ###print \"\\t\\t\\t (<change>) an_operon:\", an_operon\n",
      "                \n",
      "                visited_operon_list = previously_visited_operon_list + [an_operon]\n",
      "                \n",
      "                ###print \"\\t\\t\\t(<after>) visited_operon_list:\", visited_operon_list\n",
      "\n",
      "                ###print \"\\t\\t\\t <SPECIES>\"\n",
      "                ###print \"\\t\\t\\t (<before>) previously_visited_species_list:\", previously_visited_species_list\n",
      "                \n",
      "                just_produced_species_list = output_dictionary[an_operon]\n",
      "                \n",
      "                ###print \"\\t\\t\\t (<change>) just produced species by\", \"operon (ope_id\", an_operon, \"):\", just_produced_species_list                \n",
      "                \n",
      "                visited_species_list = previously_visited_species_list + uniquely_merge_list_of_lists(just_produced_species_list)\n",
      "                visited_species_list = remove_duplicates_within_list(visited_species_list)\n",
      "                \n",
      "                ###print \"\\t\\t\\t (<after>) visited_species_list:\", visited_species_list\n",
      "                \n",
      "                ###print \"\\t\\t\\t Can\", output_species_list, \"be found in\", just_produced_species_list,\"?\"\n",
      "                \n",
      "                if match_any_list(just_produced_species_list, output_species_list):\n",
      "                    \n",
      "                    ###print \"\\n\\t\\t\\t\\t !!!OUTPUT SPECIES FOUND!!! \\n\"\n",
      "                    \n",
      "                    final_operon_path_list.append(visited_operon_list)\n",
      "                    final_species_path_list.append(list(visited_species_list))\n",
      "                    \n",
      "                    ###print \"\\n\\t\\t\\t\\t final_operon_path_list:\", final_operon_path_list\n",
      "                    ###print \"\\t\\t\\t\\t final_species_path_list:\", final_species_path_list\n",
      "                    \n",
      "                else:        \n",
      "                    #if an_operon not in memory_operon:\n",
      "                    ###print \"\\t\\t\\t\\t operon(ope_id:\", an_operon, \") does not produce output species, but\", just_produced_species_list, \"-> path_queue\"\n",
      "                    path_queue.append( (visited_operon_list,uniquely_merge_list_of_lists(just_produced_species_list)) )\n",
      "                    memory_species.extend(visited_species_list)\n",
      "                    memory_species = remove_duplicates_within_list(memory_species)\n",
      "                    memory_species_queue.append(visited_species_list)\n",
      "                        \n",
      "                        \n",
      "                        \n",
      "                        \n",
      "                        \n",
      "                    # [ [[ope_path1],[spe_path1]], [[ope_path2],[spe_path2]], ...]\n",
      "                    memory_path_queue.append( [visited_operon_list,uniquely_merge_list_of_lists(just_produced_species_list)] )\n",
      "                    ###print \" \\n\\t\\t\\t\\t memory_path_queue:\", memory_path_queue\n",
      "                    ###print \"\\n\\n\\n\\n\\n\"\n",
      "                        \n",
      "                        \n",
      "                        \n",
      "                        \n",
      "                        \n",
      "                    #else:\n",
      "                        #print \"\\t\\t\\t\\t This operon(ope_id:\", an_operon, \") is already in memory_operon:\", memory_operon\n",
      "   \n",
      "                memory_operon.append(an_operon)\n",
      "                memory_operon = remove_duplicates_within_list(memory_operon)\n",
      "                \n",
      "                ###print \"\\n\\t\\t\\t\\t\\t ######### <per operon> path_queue:\", path_queue, len(path_queue)\n",
      "                ###print \"\\t\\t\\t\\t\\t ######### <per operon> memory_operon:\", memory_operon \n",
      "                ###print \"\\t\\t\\t\\t\\t ######### <per operon> memory_species:\", memory_species\n",
      "                ###print \"\\t\\t\\t\\t\\t ######### <per operon> memory_species_queue:\", memory_species_queue, len(memory_species_queue)\n",
      "                ###print \"\\n\\n\"\n",
      "    \n",
      "    # if there is species produced, run sbider_path_aggr(...).\n",
      "    if len(memory_species) > 0:\n",
      "        print \"$$$ sbider_path_aggr $$$\"\n",
      "        sbider_path_aggr(input_dictionary,\n",
      "                         output_dictionary,\n",
      "                         input_species_list,\n",
      "                         output_species_list,\n",
      "                         path_queue,\n",
      "                         final_operon_path_list,\n",
      "                         final_species_path_list,\n",
      "                         memory_operon,\n",
      "                         memory_species,\n",
      "                         memory_species_queue,\n",
      "                         memory_path_queue)\n",
      "        \n",
      "        \n",
      "    if len(final_operon_path_list) > 0:\n",
      "         final_operon_path_list = remove_duplicated_lists_within_a_list_of_lists(final_operon_path_list)\n",
      "    if len(final_species_path_list) > 0:\n",
      "         final_species_path_list = remove_duplicated_lists_within_a_list_of_lists(final_species_path_list)\n",
      "    return final_operon_path_list, final_species_path_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sbider_path_aggr(input_dictionary,\n",
      "                     output_dictionary,\n",
      "                     input_species_list,\n",
      "                     output_species_list,\n",
      "                     path_queue,\n",
      "                     final_operon_path_list,\n",
      "                     final_species_path_list,\n",
      "                     memory_operon,\n",
      "                     memory_species,\n",
      "                     memory_species_queue,\n",
      "                     memory_path_queue):\n",
      "    ###print \"@\" * 99\n",
      "    ###print \"********* path_queue:\", path_queue, len(path_queue)\n",
      "    ###print \"********* final_operon_path_list:\", final_operon_path_list\n",
      "    ###print \"********* final_species_path_list:\", final_species_path_list\n",
      "    ###print \"********* memory_operon:\", memory_operon\n",
      "    ###print \"********* memory_species:\", memory_species\n",
      "    ###print \"********* memory_species_queue:\", memory_species_queue, len(memory_species_queue)\n",
      "    ###print \"@\" * 99\n",
      "    \n",
      "    ###print \"\\t operons yet to be visited:\", set(input_dictionary.keys()) - set(memory_operon)\n",
      "\n",
      "    for an_operon in set(input_dictionary.keys()) - set(memory_operon):\n",
      "        \n",
      "        activation_requirement = input_dictionary[an_operon]\n",
      "        \n",
      "        ###print \"\\n\\t\\t potential operon & its input species:\", an_operon, \" & \", activation_requirement\n",
      "        ###print \"\\t\\t (ACTIVATE?)Does species\", memory_species, \"match an_operon's input species:\", activation_requirement,\"?\"\n",
      "\n",
      "        if match_any_list(activation_requirement, memory_species) == True:\n",
      "            just_produced_species_list = output_dictionary[an_operon]\n",
      "            ###print \"\\t\\t\\t ACTIVATED\"\n",
      "            ###print \"\\t\\t\\t just_produced_species_list:\", just_produced_species_list\n",
      "\n",
      "\n",
      "            ###print \"\\t\\t\\t Can\", output_species_list, \"be found in\", just_produced_species_list,\"?\"\n",
      "            \n",
      "            if match_any_list(just_produced_species_list, output_species_list):\n",
      "                ###print \"\\n\\t\\t\\t\\t !!!OUTPUT SPECIES FOUND!!! \\n\"\n",
      "                final_operon_path_list.append([an_operon])\n",
      "                final_species_path_list.append(uniquely_merge_list_of_lists(just_produced_species_list))\n",
      "                ###print \"\\n\\t\\t\\t\\t final_operon_path_list:\", final_operon_path_list\n",
      "                ###print \"\\t\\t\\t\\t final_species_path_list:\", final_species_path_list\n",
      "\n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                #an_operon & activation_requirement\n",
      "                # memory_path_queue trick...\n",
      "                             \n",
      "                matched_input_requirement = get_matching_list(activation_requirement, memory_species)\n",
      "                ###print \" \\n\\t\\t\\t\\t an_operon - matched_input_requirement:\", an_operon, \"-\", matched_input_requirement\n",
      "                ###print \"\\n\\n\\n\\n\\n\"\n",
      "                \n",
      "                \n",
      "                \n",
      "\n",
      "                \n",
      "            else:\n",
      "                if an_operon not in memory_operon:\n",
      "                    ###print \"\\t\\t\\t\\t operon(ope_id:\", an_operon, \") does not produce output species, but\", just_produced_species_list, \"-> path_queue\"\n",
      "                    path_queue.append( ([an_operon],uniquely_merge_list_of_lists(just_produced_species_list)) )\n",
      "                    memory_species.extend(uniquely_merge_list_of_lists(just_produced_species_list))\n",
      "                    memory_species = remove_duplicates_within_list(memory_species)\n",
      "                    memory_species_queue.append(uniquely_merge_list_of_lists(just_produced_species_list))\n",
      "                    \n",
      "                \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    # [ [[ope_path1],[spe_path1]], [[ope_path2],[spe_path2]], ...]\n",
      "                    memory_path_queue.append( [[an_operon],uniquely_merge_list_of_lists(just_produced_species_list)] )\n",
      "                    ###print \" \\n\\t\\t\\t\\t memory_path_queue:\", memory_path_queue\n",
      "                    ###print \"\\n\\n\\n\\n\\n\"\n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                else:\n",
      "                    ###print \"\\t\\t\\t\\t This operon(ope_id:\", an_operon, \") is already in memory_operon:\", memory_operon\n",
      "\n",
      "            memory_operon.append(an_operon)\n",
      "            memory_operon = remove_duplicates_within_list(memory_operon)         \n",
      "\n",
      "            ###print \"\\n\\t\\t\\t\\t\\t ######### <per operon> path_queue:\", path_queue, len(path_queue)\n",
      "            ###print \"\\t\\t\\t\\t\\t ######### <per operon> memory_operon:\", memory_operon \n",
      "            ###print \"\\t\\t\\t\\t\\t ######### <per operon> memory_species:\", memory_species\n",
      "            ###print \"\\t\\t\\t\\t\\t ######### <per operon> memory_species_queue:\", memory_species_queue, len(memory_species_queue)\n",
      "            ###print \"\\n\\n\"\n",
      "    \n",
      "    # if there is activated operon, run sbider_path agian.\n",
      "    if len(path_queue) > 0: \n",
      "        \n",
      "        ###print \"$$$ sbider_path $$$\"\n",
      "        sbider_path(input_dictionary,\n",
      "                    output_dictionary,\n",
      "                    input_species_list,\n",
      "                    output_species_list,\n",
      "                    path_queue,\n",
      "                    final_operon_path_list,\n",
      "                    final_species_path_list,\n",
      "                    memory_operon,\n",
      "                    memory_species,\n",
      "                    memory_species_queue,\n",
      "                    memory_path_queue)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-29-2281d85cdd5b>, line 84)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-2281d85cdd5b>\"\u001b[0;36m, line \u001b[0;32m84\u001b[0m\n\u001b[0;31m    memory_operon.append(an_operon)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_path_dictionary = {'o1':[['a']],\n",
      "                         'o2':[['a']],\n",
      "                         'o3':[['i', 'v']],\n",
      "                         'o4':[['j', 'w']],\n",
      "                         'o5':[['x', 'y'], ['g']]}\n",
      "\n",
      "output_path_dictionary = {'o1':[['i']],\n",
      "                          'o2':[['j']],\n",
      "                          'o3':[['x']],\n",
      "                          'o4':[['y']],\n",
      "                          'o5':[['z']]}\n",
      "inp = ['a','v', 'w']\n",
      "outp = ['z']\n",
      "'''\n",
      "input_path_dictionary = {'o1':[['a']],\n",
      "                         'o2':[['b']],\n",
      "                         'o3':[['c']],\n",
      "                         'o4':[['d']],\n",
      "                         'o5':[['e']]}\n",
      "\n",
      "output_path_dictionary = {'o1':[['b']],\n",
      "                          'o2':[['c']],\n",
      "                          'o3':[['d']],\n",
      "                          'o4':[['e']],\n",
      "                          'o5':[['f']]}\n",
      "\n",
      "inp = ['a']\n",
      "outp = ['f']\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "\"\\ninput_path_dictionary = {'o1':[['a']],\\n                         'o2':[['b']],\\n                         'o3':[['c']],\\n                         'o4':[['d']],\\n                         'o5':[['e']]}\\n\\noutput_path_dictionary = {'o1':[['b']],\\n                          'o2':[['c']],\\n                          'o3':[['d']],\\n                          'o4':[['e']],\\n                          'o5':[['f']]}\\n\\ninp = ['a']\\noutp = ['f']\\n\""
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_sbider_path(input_path_dictionary, output_path_dictionary, inp, outp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "$$$ sbider_path_aggr $$$\n",
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
        "********* path_queue: [] 0\n",
        "********* final_operon_path_list: []\n",
        "********* final_species_path_list: []\n",
        "********* memory_operon: ['o2', 'o1']\n",
        "********* memory_species: ['a', 'v', 'w', 'j', 'i']\n",
        "********* memory_species_queue: [] 0\n",
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
        "\t operons yet to be visited: set(['o5', 'o4', 'o3'])\n",
        "\n",
        "\t\t potential operon & its input species: o5  &  [['x', 'y'], ['g']]\n",
        "\t\t (ACTIVATE?)Does species ['a', 'v', 'w', 'j', 'i'] match an_operon's input species: [['x', 'y'], ['g']] ?\n",
        "\n",
        "\t\t potential operon & its input species: o4  &  [['j', 'w']]\n",
        "\t\t (ACTIVATE?)Does species ['a', 'v', 'w', 'j', 'i'] match an_operon's input species: [['j', 'w']] ?\n",
        "\t\t\t ACTIVATED\n",
        "\t\t\t just_produced_species_list: [['y']]\n",
        "\t\t\t Can ['z'] be found in [['y']] ?\n",
        "\t\t\t\t operon(ope_id: o4 ) does not produce output species, but [['y']] -> path_queue\n",
        " \n",
        "\t\t\t\t memory_path_queue: [[['o2'], ['j']], [['o1'], ['i']], [['o4'], ['y']]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t\t\t\t ######### <per operon> path_queue: [(['o4'], ['y'])] 1\n",
        "\t\t\t\t\t ######### <per operon> memory_operon: ['o2', 'o1', 'o4']\n",
        "\t\t\t\t\t ######### <per operon> memory_species: ['a', 'v', 'w', 'j', 'i', 'y']\n",
        "\t\t\t\t\t ######### <per operon> memory_species_queue: [['y']] 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t potential operon & its input species: o3  &  [['i', 'v']]\n",
        "\t\t (ACTIVATE?)Does species ['a', 'v', 'w', 'j', 'i', 'y'] match an_operon's input species: [['i', 'v']] ?\n",
        "\t\t\t ACTIVATED\n",
        "\t\t\t just_produced_species_list: [['x']]\n",
        "\t\t\t Can ['z'] be found in [['x']] ?\n",
        "\t\t\t\t operon(ope_id: o3 ) does not produce output species, but [['x']] -> path_queue\n",
        " \n",
        "\t\t\t\t memory_path_queue: [[['o2'], ['j']], [['o1'], ['i']], [['o4'], ['y']], [['o3'], ['x']]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t\t\t\t ######### <per operon> path_queue: [(['o4'], ['y']), (['o3'], ['x'])] 2\n",
        "\t\t\t\t\t ######### <per operon> memory_operon: ['o2', 'o1', 'o4', 'o3']\n",
        "\t\t\t\t\t ######### <per operon> memory_species: ['a', 'v', 'w', 'j', 'i', 'y', 'x']\n",
        "\t\t\t\t\t ######### <per operon> memory_species_queue: [['y'], ['x']] 2\n",
        "\n",
        "\n",
        "\n",
        "$$$ sbider_path $$$\n",
        "$$$ sbider_path_aggr $$$\n",
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
        "********* path_queue: [] 0\n",
        "********* final_operon_path_list: []\n",
        "********* final_species_path_list: []\n",
        "********* memory_operon: ['o2', 'o1', 'o4', 'o3']\n",
        "********* memory_species: ['a', 'v', 'w', 'j', 'i', 'y', 'x']\n",
        "********* memory_species_queue: [] 0\n",
        "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
        "\t operons yet to be visited: set(['o5'])\n",
        "\n",
        "\t\t potential operon & its input species: o5  &  [['x', 'y'], ['g']]\n",
        "\t\t (ACTIVATE?)Does species ['a', 'v', 'w', 'j', 'i', 'y', 'x'] match an_operon's input species: [['x', 'y'], ['g']] ?\n",
        "\t\t\t ACTIVATED\n",
        "\t\t\t just_produced_species_list: [['z']]\n",
        "\t\t\t Can ['z'] be found in [['z']] ?\n",
        "\n",
        "\t\t\t\t !!!OUTPUT SPECIES FOUND!!! \n",
        "\n",
        "\n",
        "\t\t\t\t final_operon_path_list: [['o5']]\n",
        "\t\t\t\t final_species_path_list: [['z']]\n",
        " \n",
        "\t\t\t\t an_operon - matched_input_requirement: o5 - [['x', 'y']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t\t\t\t ######### <per operon> path_queue: [] 0\n",
        "\t\t\t\t\t ######### <per operon> memory_operon: ['o2', 'o1', 'o4', 'o3', 'o5']\n",
        "\t\t\t\t\t ######### <per operon> memory_species: ['a', 'v', 'w', 'j', 'i', 'y', 'x']\n",
        "\t\t\t\t\t ######### <per operon> memory_species_queue: [] 0\n",
        "\n",
        "\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "([['o5']], [['z']])"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "activated = [[['o2'], ['j']], [['o1'], ['i']], [['o4'], ['y']], [['o3'], ['x']]]\n",
      "final_op = 'o5'\n",
      "\n",
      "\n",
      "\n",
      "def sbider_path_memory(input_dictionary,\n",
      "                       activated_paths,\n",
      "                       start_operon):\n",
      "    \n",
      "    root = node(start_operon) # node\n",
      "    \n",
      "    temp_queue = [] # for building tree\n",
      "    temp_queue.append(root)\n",
      "        \n",
      "    while len(activated_paths) > 0:\n",
      "        print \"$$$ sbider_path_memory $$$ \\n\"\n",
      "        print \"sbider_path_memory: activated_paths: \\t\", activated_paths\n",
      "        \n",
      "        from_node = temp_queue.pop(0)\n",
      "        print \"sbider_path_memory: temp_queue: \\t\", temp_queue\n",
      "        from_operon = from_node.value\n",
      "        print \"sbider_path_memory: from_operon: \\t\", from_operon\n",
      "        \n",
      "        children_operon = sbider_path_memory_search(input_dictionary,\n",
      "                                                    activated_paths,\n",
      "                                                    from_operon)        \n",
      "        print \"sbider_path_memory: children_operon: \\t\", children_operon\n",
      "\n",
      "        merged_children_operon = uniquely_merge_list_of_lists(children_operon)\n",
      "        \n",
      "        for a_merged_child_operon in merged_children_operon:\n",
      "            print \"sbider_path_memory: a_merged_child_operon: \\t\", a_merged_child_operon\n",
      "            a_child_node = node(a_merged_child_operon)\n",
      "            from_node.append_child(a_child_node)\n",
      "            temp_queue.append(a_child_node)\n",
      "            \n",
      "        print \"*\" * 99\n",
      "    return root.get_path_from_leaves()\n",
      "\n",
      "\n",
      "\n",
      "def sbider_path_memory_search(input_dictionary,\n",
      "                              activated_paths,\n",
      "                              from_operon):\n",
      "    print \"\\t ***sbider_path_memory_search*** \\n\"\n",
      "    print \"\\t sbider_path_memory: activated_paths: \\t\", activated_paths\n",
      "    print \"\\t sbider_path_memory: from_operon: \\t\", from_operon\n",
      "    final_operon_activated_requirement = input_dictionary[from_operon]\n",
      "    print \"\\t final_operon_requirement: \\t\", final_operon_activated_requirement\n",
      "    print\n",
      "    activated_ope_dic = {}\n",
      "    activated_spe_dic = {}\n",
      "    \n",
      "    for path_idx, ope_spe_path in enumerate(activated_paths):\n",
      "        print \"\\t\\t path_idx - ope_spe_path: \\t\", path_idx, \"-\", ope_spe_path\n",
      "        activated_ope_dic[path_idx] = ope_spe_path[0] # ope\n",
      "        activated_spe_dic[path_idx] = ope_spe_path[1] # spe\n",
      "\n",
      "    print \"\\t activated_ope_dic: \\t\", activated_ope_dic\n",
      "    print \"\\t activated_spe_dic: \\t\", activated_spe_dic\n",
      "    print\n",
      "\n",
      "    activating_ope_list = []\n",
      "    counter = 0\n",
      "    for path_idx, spe_produced in activated_spe_dic.items():\n",
      "        print \"\\t\\t path_idx - spe_produced: \\t\", path_idx, \"-\", spe_produced\n",
      "\n",
      "        for a_spe_produced in spe_produced:\n",
      "            print \"\\t\\t\\t a_spe_produced: \\t\", a_spe_produced\n",
      "            for and_spe_required in final_operon_activated_requirement:\n",
      "                print \"\\t\\t\\t\\t looking at\", and_spe_required, \"in\", final_operon_activated_requirement\n",
      "                if a_spe_produced in and_spe_required:\n",
      "                    # does not have to be full activation.\n",
      "                    print \"\\t\\t\\t\\t\", a_spe_produced, \"can activate\", and_spe_required, \"!\"\n",
      "                    activating_ope_list.append(activated_ope_dic.get(path_idx))\n",
      "                    del activated_paths[path_idx - counter] # do not look at this path idx again\n",
      "                    counter = counter + 1\n",
      "                else:\n",
      "                    print \"\\t\\t\\t\\t \", a_spe_produced, \"cannot activate\", and_spe_required, \"...\"\n",
      "    print \"\\t activating_ope_list (growing):\", activating_ope_list\n",
      "    print \"\\t activated_paths (shrinking):\", activated_paths\n",
      "    print\n",
      "    \n",
      "    return activating_ope_list\n",
      "\n",
      "\n",
      "\n",
      "root = sbider_path_memory(input_path_dictionary, activated, final_op)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "$$$ sbider_path_memory $$$ \n",
        "\n",
        "sbider_path_memory: activated_paths: \t[[['o2'], ['j']], [['o1'], ['i']], [['o4'], ['y']], [['o3'], ['x']]]\n",
        "sbider_path_memory: temp_queue: \t[]\n",
        "sbider_path_memory: from_operon: \to5\n",
        "\t ***sbider_path_memory_search*** \n",
        "\n",
        "\t sbider_path_memory: activated_paths: \t[[['o2'], ['j']], [['o1'], ['i']], [['o4'], ['y']], [['o3'], ['x']]]\n",
        "\t sbider_path_memory: from_operon: \to5\n",
        "\t final_operon_requirement: \t[['x', 'y'], ['g']]\n",
        "\n",
        "\t\t path_idx - ope_spe_path: \t0 - [['o2'], ['j']]\n",
        "\t\t path_idx - ope_spe_path: \t1 - [['o1'], ['i']]\n",
        "\t\t path_idx - ope_spe_path: \t2 - [['o4'], ['y']]\n",
        "\t\t path_idx - ope_spe_path: \t3 - [['o3'], ['x']]\n",
        "\t activated_ope_dic: \t{0: ['o2'], 1: ['o1'], 2: ['o4'], 3: ['o3']}\n",
        "\t activated_spe_dic: \t{0: ['j'], 1: ['i'], 2: ['y'], 3: ['x']}\n",
        "\n",
        "\t\t path_idx - spe_produced: \t0 - ['j']\n",
        "\t\t\t a_spe_produced: \tj\n",
        "\t\t\t\t looking at ['x', 'y'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\t  j cannot activate ['x', 'y'] ...\n",
        "\t\t\t\t looking at ['g'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\t  j cannot activate ['g'] ...\n",
        "\t\t path_idx - spe_produced: \t1 - ['i']\n",
        "\t\t\t a_spe_produced: \ti\n",
        "\t\t\t\t looking at ['x', 'y'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\t  i cannot activate ['x', 'y'] ...\n",
        "\t\t\t\t looking at ['g'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\t  i cannot activate ['g'] ...\n",
        "\t\t path_idx - spe_produced: \t2 - ['y']\n",
        "\t\t\t a_spe_produced: \ty\n",
        "\t\t\t\t looking at ['x', 'y'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\ty can activate ['x', 'y'] !\n",
        "\t\t\t\t looking at ['g'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\t  y cannot activate ['g'] ...\n",
        "\t\t path_idx - spe_produced: \t3 - ['x']\n",
        "\t\t\t a_spe_produced: \tx\n",
        "\t\t\t\t looking at ['x', 'y'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\tx can activate ['x', 'y'] !\n",
        "\t\t\t\t looking at ['g'] in [['x', 'y'], ['g']]\n",
        "\t\t\t\t  x cannot activate ['g'] ...\n",
        "\t activating_ope_list (growing): [['o4'], ['o3']]\n",
        "\t activated_paths (shrinking): [[['o2'], ['j']], [['o1'], ['i']]]\n",
        "\n",
        "sbider_path_memory: children_operon: \t[['o4'], ['o3']]\n",
        "sbider_path_memory: a_merged_child_operon: \to3\n",
        "sbider_path_memory: a_merged_child_operon: \to4\n",
        "***************************************************************************************************\n",
        "$$$ sbider_path_memory $$$ \n",
        "\n",
        "sbider_path_memory: activated_paths: \t[[['o2'], ['j']], [['o1'], ['i']]]\n",
        "sbider_path_memory: temp_queue: \t['o4'\n",
        "]\n",
        "sbider_path_memory: from_operon: \to3\n",
        "\t ***sbider_path_memory_search*** \n",
        "\n",
        "\t sbider_path_memory: activated_paths: \t[[['o2'], ['j']], [['o1'], ['i']]]\n",
        "\t sbider_path_memory: from_operon: \to3\n",
        "\t final_operon_requirement: \t[['i', 'v']]\n",
        "\n",
        "\t\t path_idx - ope_spe_path: \t0 - [['o2'], ['j']]\n",
        "\t\t path_idx - ope_spe_path: \t1 - [['o1'], ['i']]\n",
        "\t activated_ope_dic: \t{0: ['o2'], 1: ['o1']}\n",
        "\t activated_spe_dic: \t{0: ['j'], 1: ['i']}\n",
        "\n",
        "\t\t path_idx - spe_produced: \t0 - ['j']\n",
        "\t\t\t a_spe_produced: \tj\n",
        "\t\t\t\t looking at ['i', 'v'] in [['i', 'v']]\n",
        "\t\t\t\t  j cannot activate ['i', 'v'] ...\n",
        "\t\t path_idx - spe_produced: \t1 - ['i']\n",
        "\t\t\t a_spe_produced: \ti\n",
        "\t\t\t\t looking at ['i', 'v'] in [['i', 'v']]\n",
        "\t\t\t\ti can activate ['i', 'v'] !\n",
        "\t activating_ope_list (growing): [['o1']]\n",
        "\t activated_paths (shrinking): [[['o2'], ['j']]]\n",
        "\n",
        "sbider_path_memory: children_operon: \t[['o1']]\n",
        "sbider_path_memory: a_merged_child_operon: \to1\n",
        "***************************************************************************************************\n",
        "$$$ sbider_path_memory $$$ \n",
        "\n",
        "sbider_path_memory: activated_paths: \t[[['o2'], ['j']]]\n",
        "sbider_path_memory: temp_queue: \t['o1'\n",
        "]\n",
        "sbider_path_memory: from_operon: \to4\n",
        "\t ***sbider_path_memory_search*** \n",
        "\n",
        "\t sbider_path_memory: activated_paths: \t[[['o2'], ['j']]]\n",
        "\t sbider_path_memory: from_operon: \to4\n",
        "\t final_operon_requirement: \t[['j', 'w']]\n",
        "\n",
        "\t\t path_idx - ope_spe_path: \t0 - [['o2'], ['j']]\n",
        "\t activated_ope_dic: \t{0: ['o2']}\n",
        "\t activated_spe_dic: \t{0: ['j']}\n",
        "\n",
        "\t\t path_idx - spe_produced: \t0 - ['j']\n",
        "\t\t\t a_spe_produced: \tj\n",
        "\t\t\t\t looking at ['j', 'w'] in [['j', 'w']]\n",
        "\t\t\t\tj can activate ['j', 'w'] !\n",
        "\t activating_ope_list (growing): [['o2']]\n",
        "\t activated_paths (shrinking): []\n",
        "\n",
        "sbider_path_memory: children_operon: \t[['o2']]\n",
        "sbider_path_memory: a_merged_child_operon: \to2\n",
        "***************************************************************************************************\n",
        "leaf_list: [<class '__main__.node'>, <class '__main__.node'>]\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "type object 'node' has no attribute 'value'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-32-3d3be45f498b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msbider_path_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-32-3d3be45f498b>\u001b[0m in \u001b[0;36msbider_path_memory\u001b[0;34m(input_dictionary, activated_paths, start_operon)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path_from_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-23-91a7d3c95db1>\u001b[0m in \u001b[0;36mget_path_from_leaves\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"leaf_list:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mleaf_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mcurrent_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mpointer_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mpointer_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: type object 'node' has no attribute 'value'"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class node(object):\n",
      "    def __init__(self, value):\n",
      "        self.value = value\n",
      "        self.children = []\n",
      "        self.parent = None\n",
      "    \n",
      "    def __repr__(self, level=0):\n",
      "        ret = \"\\t\"*level+repr(self.value)+\"\\n\"\n",
      "        for child in self.children:\n",
      "            ret += child.__repr__(level+1)\n",
      "        return ret\n",
      "\n",
      "    def append_child(self, obj):\n",
      "        self.children.append(obj)\n",
      "        obj.parent = self\n",
      "    \n",
      "    def get_leaf(self):\n",
      "        return uniquely_merge_multi_dimentional_list_of_lists(self.get_leaf_helper())\n",
      "    \n",
      "    def get_leaf_helper(self):\n",
      "        leaf_list = []\n",
      "        if self.children != []:\n",
      "            for a_child_node in self.children:\n",
      "                leaf_list.append(a_child_node.get_leaf())\n",
      "            print \"leaf_list\", leaf_list\n",
      "            return leaf_list\n",
      "        return self\n",
      "    \n",
      "    def get_leaves(self):\n",
      "        node_queue = [self]\n",
      "        leaves_list = []\n",
      "        while len(node_queue) > 0:\n",
      "            current_node = node_queue.pop(0)\n",
      "            if len(current_node.children) == 0:\n",
      "                leaves_list.append(node)\n",
      "            else:\n",
      "                for child in current_node.children:\n",
      "                    node_queue.append(child)\n",
      "        return leaves_list\n",
      "                    \n",
      "    def get_path(self):\n",
      "        my_path = []\n",
      "        print \"self.value\", self.value\n",
      "        print \"len(self.children)\", len(self.children)\n",
      "        if self.children != []:\n",
      "            for a_child_node in self.children:\n",
      "                print \"a_child:\", a_child_node.value\n",
      "                print \"a_child:\", a_child_node.get_path()\n",
      "\n",
      "                my_path = my_path + a_child_node.get_path()\n",
      "        my_path.insert(0,self.value)\n",
      "        return my_path\n",
      "    \n",
      "    def get_path_from_leaves(self):\n",
      "        all_paths = []\n",
      "        leaf_list = self.get_leaves()\n",
      "        print \"leaf_list:\", leaf_list\n",
      "        for leaf in leaf_list:\n",
      "            current_path = [leaf.value]\n",
      "            pointer_node = leaf\n",
      "            while pointer_node.parent != self:\n",
      "                current_path.append(pointer_node.parent.value)\n",
      "                pointer_node = pointer_node.parent\n",
      "            current_path.append(self.value)\n",
      "            all_paths.append(current_path)\n",
      "        return all_paths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_node = node(\"hi\")\n",
      "print new_node.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hi\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}