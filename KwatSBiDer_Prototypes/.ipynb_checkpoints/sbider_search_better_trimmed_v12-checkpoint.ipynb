{
 "metadata": {
  "name": "",
  "signature": "sha256:f010577b905211a287dbb57499947bc957f6d0c6e97d32517e4a1bb4e83b53eb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools as it\n",
      "import matplotlib.pyplot as plt\n",
      "import networkx as nx\n",
      "import weakref"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class node(object):\n",
      "    def __init__(self, value):\n",
      "        self.value = value\n",
      "        ###print \"node.__init__(self, value): self, value:\", value, type(value)\n",
      "        self.children = []\n",
      "        self.parent = None\n",
      "    \n",
      "    def __repr__(self, level=0):\n",
      "        ret = \"\\t\"*level+repr(self.value)+\"\\n\"\n",
      "        for child in self.children:\n",
      "            ret += child.__repr__(level+1)\n",
      "        return ret\n",
      "    \n",
      "    def append_child(self, obj):\n",
      "        ###print \"append_child: obj: \\t\", obj, type(obj)\n",
      "        children_values = []\n",
      "        for child in self.children:\n",
      "            children_values.append(child.value)\n",
      "        obj_value = obj.value\n",
      "        if obj_value not in children_values:\n",
      "            self.children.append(obj)\n",
      "            if type(obj) == node:\n",
      "                ###print \"append_child: obj is an instance of node\"\n",
      "                obj.parent = self\n",
      "            ###else:\n",
      "                ###print \"append_child: obj\", obj, \"is NOT an instance of node\"\n",
      "    \n",
      "    def get_all_leaf(self):\n",
      "        leaf_list = []\n",
      "        ###print \"get_all_leaf: self.children:\", self.children, len(self.children)\n",
      "        if len(self.children) > 0:\n",
      "            for child_node in self.children:                \n",
      "                leaf_list.extend(child_node.get_all_leaf())\n",
      "            ###print \"get_all_leaf: returning leaf_list: before merge \\t\", leaf_list\n",
      "            leaf_list = uniquely_merge_multi_dimentional_list_of_lists(leaf_list)\n",
      "            ###print \"get_all_leaf: returning leaf_list: after merge \\t\", leaf_list\n",
      "            ###print \"@get_all_leaf: returning leaf_list: \\t\", leaf_list, type(leaf_list)\n",
      "            return leaf_list\n",
      "        ###print \"@get_all_leaf: no children so returning self: \\t\", self, type(self)\n",
      "        return [self]\n",
      "    \n",
      "    def get_path_from_all_leaf(self):\n",
      "        print \"*get_path_from_all_leaf: self\", self\n",
      "        path_list = []\n",
      "        leaf_list = self.get_all_leaf()\n",
      "        print \"**get_path_from_all_leaf: leaf_list \\n\", leaf_list, len(leaf_list)\n",
      "        \n",
      "        if len(leaf_list) == 1 and self in leaf_list:\n",
      "            path_list.append([self.value])\n",
      "            return path_list\n",
      "    \n",
      "        elif len(leaf_list) > 0:\n",
      "            for leaf in leaf_list:\n",
      "                path = []\n",
      "                print \"***get_path_from_all_leaf: a leaf in leaf_list:\", leaf, type(leaf)\n",
      "                path.append(leaf.value)\n",
      "                pointer_node = leaf\n",
      "                while pointer_node.parent != self:\n",
      "                    path.append(pointer_node.parent.value)\n",
      "                    pointer_node = pointer_node.parent\n",
      "                path.append(self.value)\n",
      "                path_list.append(path)\n",
      "            return path_list\n",
      "        else:\n",
      "            return []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_duplicates_within_list(seq):\n",
      "    seen = set()\n",
      "    seen_add = seen.add\n",
      "    return [ x for x in seq if not (x in seen or seen_add(x))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_is_type(lst, typ):\n",
      "    \"\"\"\n",
      "    Check if all elements in a list is the same specified type.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(lst) != list:\n",
      "        raise TypeError(\"list_is_type(lst, typ): lst is not a list\")\n",
      "    elif len(lst) <= 0:\n",
      "        raise ValueError(\"list_is_type(lst, typ): lst is empty\")\n",
      "    return all(isinstance(x,typ) for x in lst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_duplicated_lists_within_a_list_of_lists(list_of_lists):\n",
      "    \"\"\"\n",
      "    Removes any duplicated lists, which contain same elements in same order, within a list of lists.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        list_of_lists.sort()\n",
      "        trimmed = list(list_of_lists for list_of_lists,_ in it.groupby(list_of_lists))\n",
      "        return trimmed\n",
      "    else:\n",
      "        raise TypeError(\"remove_duplicated_lists_within_a_list_of_lists(list_of_lists): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uniquely_merge_list_of_lists(list_of_lists):\n",
      "    \"\"\"\n",
      "    Merge unique elements from lists within a list.\n",
      "    \n",
      "    Argument:\n",
      "        list_of_lists - a list that contains multiple lists.\n",
      "    \n",
      "    Return:\n",
      "        a new list that contains unique elements from all lists within a list of lists.\n",
      "    \"\"\"   \n",
      "    \n",
      "    if type(list_of_lists) == list and len(list_of_lists) > 0:\n",
      "        \n",
      "        if list_is_type(list_of_lists, list) == True:\n",
      "            remove_duplicated_lists_within_a_list_of_lists(list_of_lists)\n",
      "            merged_list = list(list_of_lists[0])\n",
      "            for a_list in list_of_lists[1::]:\n",
      "                    for e in a_list:\n",
      "                        if e not in merged_list:\n",
      "                            merged_list.append(e)\n",
      "            return merged_list\n",
      "        else:\n",
      "            return list(list_of_lists)\n",
      "    else:\n",
      "        return list_of_lists\n",
      "        raise TypeError(\"uniquely_merge_list_of_lists(list_of_lists): list_of_list must be a non-empty list\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uniquely_merge_multi_dimentional_list_of_lists(multi_dimentional_list_of_lists):\n",
      "    final_merged_list = uniquely_merge_list_of_lists(multi_dimentional_list_of_lists)\n",
      "    if type(final_merged_list) == list and len(final_merged_list) > 0 and list_is_type(final_merged_list, list) == True:\n",
      "        return uniquely_merge_multi_dimentional_list_of_lists(final_merged_list)\n",
      "    else:\n",
      "        return final_merged_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def elements_match(list_of_lists, lst):\n",
      "    return set(lst).issubset(uniquely_merge_multi_dimentional_list_of_lists(list_of_lists))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_matching_list(list_of_lists, lst):\n",
      "    \"\"\"\n",
      "    Get any list that match a specified list.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(lst) != list:\n",
      "        raise TypeError(\"get_matching_list(list_of_lists, lst): lst is not a list object\")\n",
      "        \n",
      "    elif type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        matching_list = []\n",
      "        matching_list_idx = []\n",
      "        \n",
      "        for idx, a_list in enumerate(list_of_lists):\n",
      "            if all([x in lst for x in a_list]) == True:\n",
      "                matching_list.append(a_list)\n",
      "                matching_idx_list.append(idx)\n",
      "        return matching_list, matching_list_idx\n",
      "    else:\n",
      "        raise TypeError(\"get_matching_list(list_of_lists, lst): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def match_any_list(list_of_lists, lst):\n",
      "    \"\"\"\n",
      "    Check if a list matches any of lists within a list.\n",
      "    \"\"\"\n",
      "    \n",
      "    matched_inp_spe, matched_inp_idx = get_matching_list(required_inp_spe, spe)\n",
      "    \n",
      "    if len(matched_inp_spe) > 0:\n",
      "        return True, matched_inp_idx_list\n",
      "    else:\n",
      "        return False, []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def activated(inp_dic, rep_dic, ope, spe_list):\n",
      "    \n",
      "    inp_trans = inp_dic[ope]\n",
      "    \n",
      "    activated, activated_inp_idx_list = match_any_list(inp_trans, spe_list)\n",
      "    \n",
      "    rep_inp_trans = rep_dic[ope]\n",
      "    rep = []\n",
      "    for activated_inp_idx in activated_inp_idx_list:\n",
      "        rep.extend(rep_inp_trans[activated_inp_idx])\n",
      "    \n",
      "    if activated:\n",
      "        return True, rep\n",
      "    else:\n",
      "        return False, rep"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reverse_index(sequence, element):\n",
      "    \"\"\"\n",
      "    Find the last index of an element in a sequence.\n",
      "    \"\"\"\n",
      "\n",
      "    for i, e in enumerate(reversed(sequence)):\n",
      "        if element == e:\n",
      "            return len(sequence) - 1 - i\n",
      "    else:\n",
      "        raise ValueError(\"r_index(sequence, element): element not in the sequence\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_parentheses(sequence):\n",
      "    \"\"\"\n",
      "    remove the outer most parentheses '()' \n",
      "    and returns the token afte the ')'\n",
      "    \"\"\"\n",
      "\n",
      "    ###print \"remove_parentheses(sequence): sequence:\", sequence\n",
      "    \n",
      "    first_opener_idx_assigned = False\n",
      "    started = False\n",
      "    counter = 0\n",
      "    \n",
      "    for idx, e in enumerate(sequence):\n",
      "        \n",
      "        ###print \"remove_parentheses(sequence): idx, e:\", idx, e\n",
      "        \n",
      "        if e == '(':\n",
      "            if started == False:\n",
      "                started = True\n",
      "            counter = counter + 1\n",
      "        elif e == ')':\n",
      "            if started == False:\n",
      "                raise ValueError(\"remove_parentheses(sequence):\\\n",
      "                                 ')' without '('\")\n",
      "            counter = counter - 1\n",
      "        if started == True:\n",
      "            if first_opener_idx_assigned == False:\n",
      "                first_opener_idx = idx\n",
      "                first_opener_idx_assigned = True\n",
      "            if counter == 0:\n",
      "                sequence.pop(idx)\n",
      "                if idx < len(sequence):\n",
      "                    element_after_last_closer = sequence[idx]\n",
      "                else:\n",
      "                    element_after_last_closer = None\n",
      "                sequence.pop(first_opener_idx)\n",
      "                return element_after_last_closer\n",
      "    else:\n",
      "        raise ValueError(\"remove_parentheses(sequence):\\\n",
      "                         sequence is empty\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_by(sequence, element):\n",
      "    \"\"\"\n",
      "    Split a sequence by a given element and store elements\n",
      "    before and after the element into a dictionary\n",
      "    \"\"\"\n",
      "    \n",
      "    element_index = sequence.index(element)\n",
      "    \n",
      "    sequence_before_element = sequence[:element_index:1]\n",
      "    sequence_after_element = sequence[element_index + 1::1]\n",
      "    \n",
      "    return {0: sequence_before_element, 1: sequence_after_element}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grammar_0(cursor, tokens):\n",
      "    '''grammar_0:= grammar_1 > grammar_1'''\n",
      "\n",
      "    ###print \"grammar_0(tokens): tokens:\",tokens\n",
      "    \n",
      "    if '>' not in tokens:\n",
      "        raise ValueError(\"grammar_0(tokens): no output\")\n",
      "        \n",
      "    else:\n",
      "        input_output_dictionary = split_by(tokens, '>')\n",
      "        \n",
      "    return grammar_output(grammar_1(cursor, input_output_dictionary[0]), grammar_1(cursor, input_output_dictionary[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grammar_1(cursor, tokens):\n",
      "    '''grammar_1:= grammar_2 or grammar_1 | grammar_2 and grammar_1 | grammar_2'''\n",
      "\n",
      "    ###print \"grammar_1(tokens): tokens:\",tokens\n",
      "    \n",
      "    if len(tokens) > 1 and tokens[1] == 'or':\n",
      "        # grammar_2 or grammar_1\n",
      "        \n",
      "        ###print \"grammar_1(tokens): detected 'or'\"\n",
      "        \n",
      "        # splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\n",
      "        or_dictionary = split_by(tokens, 'or')\n",
      "        return grammar_or(grammar_2(cursor, or_dictionary.get(0)), grammar_1(cursor, or_dictionary.get(1)))\n",
      "    \n",
      "    elif len(tokens) > 1 and tokens[1] == 'and':\n",
      "        # grammar_2 and grammar_1\n",
      "        \n",
      "        ###print \"grammar_1(tokens): detected 'and'\"\n",
      "        \n",
      "        # splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\n",
      "        and_dictionary = split_by(tokens, 'and')\n",
      "        return grammar_and(grammar_2(cursor, and_dictionary.get(0)), grammar_1(cursor, and_dictionary.get(1)))            \n",
      "    \n",
      "    else:\n",
      "        # grammar_2\n",
      "        \n",
      "        # delegates to grammar_2\n",
      "        return grammar_2(cursor, tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grammar_2(cursor, tokens):\n",
      "    '''grammar_2:= (grammar_1) or grammar_1 | (grammar_1) and grammar_1 | (grammar_1) | interactor''' \n",
      "\n",
      "    ###print \"grammar_2(tokens): tokens:\",tokens\n",
      "    \n",
      "    if len(tokens) <= 0:\n",
      "        raise ValueError(\"Invalid Syntax\")\n",
      "        \n",
      "    elif tokens[0] == \"(\":\n",
      "        # (grammar_1) or grammar_1 | (grammar_1) and grammar_1| (grammar_1)\n",
      "        \n",
      "        ###print \"grammar_2(tokens): detected '('\"\n",
      "        \n",
      "        # token after the last occuring ')'\n",
      "        token_after_last_closer = remove_parentheses(tokens)\n",
      "        \n",
      "        if token_after_last_closer == 'or':    \n",
      "            # splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\n",
      "            \n",
      "            or_dictionary = split_by(tokens, 'or')\n",
      "            return grammar_or(grammar_1(cursor, or_dictionary.get(0)), grammar_1(cursor, or_dictionary.get(1)))\n",
      "        \n",
      "        elif token_after_last_closer == 'and':\n",
      "            # splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\n",
      "            \n",
      "            and_dictionary = split_by(tokens, 'and')\n",
      "            return grammar_and(grammar_1(and_dictionary.get(0)), grammar_1(and_dictionary.get(1)))\n",
      "        \n",
      "        else:\n",
      "            # delegates to interactor\n",
      "            return grammar_1(cursor, tokens)\n",
      "        \n",
      "    else:\n",
      "        # interactor\n",
      "        \n",
      "        # delegates to interactor\n",
      "        return interactor(cursor, tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def interactor(cursor, token):\n",
      "    '''species'''\n",
      "    \n",
      "    ###print \"interactor(token): token:\", token    \n",
      "\n",
      "    species = token[0]\n",
      "    \n",
      "    ###print \"interactor(token): species:\", species\n",
      "    ###print \"interactor(token): species id:\", db_get_species_id_from_name(cursor, species)\n",
      "    return [[db_get_species_id_from_name(cursor, species)]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grammar_output(tokens1, tokens2):                                                                      \n",
      "    \"\"\"Grammar for '>'.                                                                              \n",
      "    \n",
      "    Argument(s):\n",
      "        tokens1 - desctiption                                                                              \n",
      "        tokens2 - desctiption                                                                              \n",
      "        \n",
      "        \n",
      "    Return:                                                                                                \n",
      "        return description                                                                                 \n",
      "    \"\"\"                                                                                                    \n",
      "    \n",
      "    grammar_output_dict = {}                                                                               \n",
      "    \n",
      "    ###print \"grammar_output(tokens1, tokens2): tokens1 - tokens2:\", tokens1, \" - \", tokens2\n",
      "    ###print \"grammar_output(tokens1, tokens2): tokens1 - tokens2:\", type(tokens1), \" - \", type(tokens2)\n",
      "    for token1 in tokens1:\n",
      "        grammar_output_dict[tuple(token1)] = tuple(tokens2)                                                      \n",
      "        \n",
      "    return grammar_output_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grammar_or(tokens1, tokens2):\n",
      "    '''or'''\n",
      "    \n",
      "    ###print \"grammar_or(tokens1, tokens2): tokens1 - tokens2:\", tokens1, \" - \", tokens2\n",
      "    \n",
      "    return tokens1 + tokens2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grammar_and(tokens1, tokens2):\n",
      "    '''and'''\n",
      "\n",
      "    grammar_and_output = []\n",
      "    \n",
      "    ###print \"grammar_and(tokens1, tokens2): tokens1 - tokens2:\", tokens1, \" - \", tokens2\n",
      "    \n",
      "    for token1 in tokens1:\n",
      "        for token2 in tokens2:\n",
      "            print [token1,token2]\n",
      "            grammar_and_output.append( uniquely_merge_list_of_lists( [token1,token2] ))\n",
      "    \n",
      "    ###print \"grammar_and(tokens1, tokens2): grammar_and_output:\", grammar_and_output\n",
      "    \n",
      "    return grammar_and_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_logic(cursor, logic_input):\n",
      "    '''parse a logic input into atomized and equivalent logics'''\n",
      "    \n",
      "    ###print \"parse_logic(logic_input): logic_input:\", logic_input\n",
      "    \n",
      "    split_logic_input = logic_input.split()\n",
      "        \n",
      "    ###print \"parse_logic(logic_input): split_logic_input:\", split_logic_input\n",
      "    \n",
      "    # begins recursive logic parse\n",
      "    return grammar_0(cursor, split_logic_input)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_plot(G):\n",
      "    \"\"\"\n",
      "    draw and plot a graph\n",
      "    \n",
      "    @param - graph: graph to be drawn and plotted\n",
      "    @param - start: list of input species\n",
      "    @param - end: list of output species\n",
      "    \"\"\"\n",
      "    nx.draw(G,\n",
      "            node_size=400,\n",
      "            node_color='#A0CBE2',\n",
      "            font_size=10,\n",
      "            font_color='blue',\n",
      "            width=1,\n",
      "            edge_color='blue',\n",
      "            style='dotted',\n",
      "            arrows=False)\n",
      "    \n",
      "    '''\n",
      "    ###print \"start_list:\",start_list\n",
      "    \n",
      "    # position is stored as node attribute data for random_geometric_graph\n",
      "    pos=nx.spring_layout(G)\n",
      "        \n",
      "    ###print \"pos:\",pos\n",
      "    \n",
      "    # list of nodes\n",
      "    operon_path = pos.keys()\n",
      "    \n",
      "    labels = {}\n",
      "    for operon in operon_path:\n",
      "        labels[operon] = str(operon)\n",
      "    \n",
      "    ###print \"operon_path:\",operon_path\n",
      "    \n",
      "    if len(start_list) > 0:\n",
      "        ncenter = start_list[0]\n",
      "    else:\n",
      "        ncenter = pos.keys()[len(pos.keys()) - 1]\n",
      "    \n",
      "    # color by path length from node near center\n",
      "    dis=nx.single_source_shortest_path_length(G,ncenter)\n",
      "    \n",
      "    print \"dis:\", dis\n",
      "    \n",
      "    plt.figure(figsize=(10,10))\n",
      "    \n",
      "    nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.4)\n",
      "    nx.draw_networkx_nodes(G,pos,nodelist=dis.keys(),\n",
      "                           node_size=800,\n",
      "                           node_color=dis.values(),\n",
      "                           cmap=plt.cm.Reds_r)\n",
      "    nx.draw_networkx_labels(G,pos,labels,font_size=16)\n",
      "\n",
      "    \n",
      "    plt.xlim(-0.05,1.05)\n",
      "    plt.ylim(-0.05,1.05)\n",
      "    plt.axis('off')\n",
      "    '''\n",
      "    \n",
      "    plt.show()\n",
      "    \n",
      "    #plt.savefig() #.png"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def expand_graph(graph, path_list):\n",
      "    '''expand networkx graph\n",
      "    \n",
      "    @param - graph: graph to be extended\n",
      "    @param - path_list: list representation of path'''\n",
      "    \n",
      "    graph.add_path(path_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_graph_from_path_list(path_list):\n",
      "    '''make networkx graph\n",
      "    \n",
      "    @param - path_list: list representation of path\n",
      "    @return - networkx directed graph'''\n",
      "    \n",
      "    graph = nx.DiGraph()\n",
      "    \n",
      "    if len(path_list) < 2:\n",
      "        graph.add_nodes_from(path_list)\n",
      "    else:\n",
      "        graph.add_path(path_list)\n",
      "        \n",
      "    return graph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_graph_from_path_dictionaries(in_path_dic_in, out_path_dic):\n",
      "    '''make networkx graph\n",
      "    \n",
      "    @param - in_path_dic_in: dictionary representation of input path\n",
      "    @param - out_path_dic: dictionary representation of output path\n",
      "    @return - networkx directed graph'''\n",
      "    \n",
      "    graph = nx.DiGraph()\n",
      "            \n",
      "    for plasmid, input_species_list in in_path_dic_in.items():\n",
      "        for species in input_species_list:\n",
      "            graph.add_edge(species, plasmid)\n",
      "    \n",
      "    for plasmid, output_species_list in out_path_dic.items():\n",
      "        for species in output_species_list:\n",
      "                graph.add_edge(plasmid, species)\n",
      "                \n",
      "    return graph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def search_sbider_path_memory(input_dictionary, activated_paths, from_operon):\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print \"~IN search_sbider_path_memory~\"\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print\n",
      "    print\n",
      "    \n",
      "    print \"search_sbider_path_memory: activated_paths:\", activated_paths\n",
      "    print\n",
      "    \n",
      "    activated_ope_dic = {}\n",
      "    activated_spe_dic = {}\n",
      "    \n",
      "    for path_idx, ope_spe_path in enumerate(activated_paths):\n",
      "        activated_ope_dic[path_idx] = ope_spe_path[0] # ope\n",
      "        activated_spe_dic[path_idx] = ope_spe_path[1] # spe\n",
      "    \n",
      "    \n",
      "    print \"search_sbider_path_memory: from_operon:\", from_operon, type(from_operon)\n",
      "    final_operon_requirement = input_dictionary[from_operon]\n",
      "    \n",
      "    activating_ope_list = []\n",
      "    \n",
      "    for path_idx, spe_produced in activated_spe_dic.items():\n",
      "        for a_spe_produced in spe_produced:\n",
      "            for and_spe_required in final_operon_requirement:\n",
      "                if a_spe_produced in and_spe_required:\n",
      "                    activating_ope_list.extend(activated_ope_dic.get(path_idx))\n",
      "    \n",
      "    print \"search_sbider_path_memory: activating_ope_list:\", activating_ope_list\n",
      "    return activating_ope_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_sbider_path_memory_tree(input_dictionary, activated_paths, start_operon):\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print \"~IN build_sbider_path_memory_tree~\"\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print\n",
      "    print\n",
      "    \n",
      "    print \"build_sbider_path_memory_tree: activated_paths:\", activated_paths\n",
      "    print\n",
      "    \n",
      "    root_ope = node(start_operon)\n",
      "\n",
      "    temp_queue_ope = []\n",
      "    temp_queue_ope.append(root_ope)\n",
      "    \n",
      "    temp_memory = []\n",
      "        \n",
      "    while len(activated_paths) > 0 and len(temp_queue_ope) > 0:\n",
      "        print \"\\t build_sbider_path_memory_tree: activated_paths in while loop:\", activated_paths\n",
      "        print \"\\t build_sbider_path_memory_tree: temp_queue_ope:\", temp_queue_ope\n",
      "        \n",
      "        from_node = temp_queue_ope.pop(0)\n",
      "        from_operon = from_node.value\n",
      "\n",
      "        print \"\\t build_sbider_path_memory_tree: ENTERING--- search_sbider_path_memory\"\n",
      "        children_operon = search_sbider_path_memory(input_dictionary, activated_paths, from_operon)\n",
      "        print \"\\t build_sbider_path_memory_tree: ---RETURNING search_sbider_path_memory\"\n",
      "        print\n",
      "        \n",
      "        if len(children_operon) > 0:\n",
      "            for child_operon in children_operon:\n",
      "                if child_operon not in temp_memory:\n",
      "                    child_node = node(child_operon)\n",
      "                    from_node.append_child(child_node)\n",
      "                    temp_queue_ope.append(child_node)\n",
      "                    temp_memory.append(child_operon)\n",
      "                    print \"\\t\\t build_sbider_path_memory_tree: root_ope UPDATED \\n\", root_ope\n",
      "                    print \"*\" * 99\n",
      "\n",
      "            print \"build_sbider_path_memory_tree: path from all ope leaf \\n\", root_ope.get_path_from_all_leaf()\n",
      "            print\n",
      "    \n",
      "    return root_ope.get_path_from_all_leaf()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_indirect_sbider_path(input_dictionary,\n",
      "                               output_dictionary,\n",
      "                               input_species_list,\n",
      "                               output_species_list,\n",
      "                               path_queue,\n",
      "                               final_operon_path_list,\n",
      "                               \n",
      "                               memory_operon,\n",
      "                               memory_species,\n",
      "                               \n",
      "                               activated_paths):\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print \"~IN build_indirect_sbider_path~\"\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print\n",
      "    print\n",
      "    \n",
      "    print \"build_indirect_sbider_path: path_queue:\", path_queue, len(path_queue)\n",
      "    print \"build_indirect_sbider_path: memory_operon:\", memory_operon \n",
      "    print \"build_indirect_sbider_path: memory_species:\", memory_species\n",
      "    print \"build_indirect_sbider_path: activated_paths:\", activated_paths\n",
      "    print\n",
      "    print \"\\t build_indirect_sbider_path: operons yet to be visited:\", set(input_dictionary.keys()) - set(memory_operon)\n",
      "    temp_memory_species = []\n",
      "    for an_operon in set(input_dictionary.keys()) - set(memory_operon):\n",
      "        print \"\\t\\t build_indirect_sbider_path: OPERON:\", an_operon\n",
      "        activation_requirement = input_dictionary[an_operon]\n",
      "        print \"\\t\\t build_indirect_sbider_path: Avtivation Requirement:\", activation_requirement\n",
      "        if match_any_list(activation_requirement, memory_species) == True:\n",
      "            print \"\\t\\t\\t build_indirect_sbider_path: Avtivation!!! of\", an_operon\n",
      "            just_produced_species = output_dictionary[an_operon]\n",
      "            just_produced_unique_species = uniquely_merge_multi_dimentional_list_of_lists(just_produced_species)            \n",
      "            \n",
      "            if match_any_list(just_produced_species, output_species_list):\n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                print \"\\t\\t\\t build_indirect_sbider_path: Match!!!!!!!!!\"\n",
      "                matched_input_requirement = get_matching_list(activation_requirement, memory_species)\n",
      "                matched_unique_input_requirement = uniquely_merge_multi_dimentional_list_of_lists(matched_input_requirement)\n",
      "                if len(activated_paths) > 1:\n",
      "                    print \"\\t\\t\\t build_indirect_sbider_path: ENTERING--- build_sbider_path_memory_tree\"\n",
      "                    ope_path_backward = build_sbider_path_memory_tree(input_dictionary,\n",
      "                                                                                     activated_paths,\n",
      "                                                                                     an_operon,\n",
      "                                                                                     )\n",
      "                    print \"\\t\\t\\t build_indirect_sbider_path: ---RETURNING build_sbider_path_memory_tree\"\n",
      "                    print\n",
      "                \n",
      "                    print \"\\t\\t\\t\\t build_direct_sbider_path: BEFORE ope:\", final_operon_path_list\n",
      "                    final_operon_path_list.extend(ope_path_backward)\n",
      "                    print \"\\t\\t\\t\\t build_direct_sbider_path: AFTER ope:\", final_operon_path_list\n",
      "            else:\n",
      "                if an_operon not in memory_operon:\n",
      "\n",
      "                    path_queue.append(([an_operon],just_produced_unique_species))\n",
      "                    \n",
      "                    memory_operon.append(an_operon)\n",
      "                    memory_operon = remove_duplicates_within_list(memory_operon)\n",
      "                    \n",
      "                    temp_memory_species.extend(just_produced_unique_species)\n",
      "                    \n",
      "                    activated_paths.append([[an_operon],just_produced_unique_species])\n",
      "            print  \n",
      "    memory_species.extend(temp_memory_species)\n",
      "    memory_species = remove_duplicates_within_list(memory_species)\n",
      "    print\n",
      "\n",
      "    # if there is activated operon, run sbider_path again.\n",
      "    if len(path_queue) > 0:\n",
      "        print \"build_indirect_sbider_path: ReENTERING--- build_direct_sbider_path\"\n",
      "        build_direct_sbider_path(input_dictionary,\n",
      "                                 output_dictionary,\n",
      "                                 input_species_list,\n",
      "                                 output_species_list,\n",
      "                                 path_queue,\n",
      "                                 final_operon_path_list,\n",
      "                                 memory_operon,\n",
      "                                 memory_species,\n",
      "                                 activated_paths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_direct_sbider_path(input_dictionary,\n",
      "                             output_dictionary,\n",
      "                             input_species_list,\n",
      "                             output_species_list,\n",
      "                             path_queue,\n",
      "                             final_operon_path_list,\n",
      "                             memory_operon,\n",
      "                             memory_species,\n",
      "                             activated_paths,\n",
      "                             indirect_flag):\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print \"~IN build_direct_sbider_path~\"\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print\n",
      "    print\n",
      "    \n",
      "    print \"build_direct_sbider_path: path_queue:\", path_queue, len(path_queue)\n",
      "    print \"build_direct_sbider_path: memory_operon:\", memory_operon \n",
      "    print \"build_direct_sbider_path: memory_species:\", memory_species\n",
      "    print \"build_direct_sbider_path: activated_paths:\", activated_paths\n",
      "    print\n",
      "    \n",
      "    while len(path_queue) != 0:\n",
      "        print \"\\t build_direct_sbider_path: path_queue in while-loop:\", path_queue, len(path_queue)\n",
      "        \n",
      "        (previously_visited_operon_list, just_previously_produced_species_list) = path_queue.pop(0)\n",
      "        \n",
      "        print \"\\t build_direct_sbider_path: operons to be visited:\", set(input_dictionary.keys()) - set(uniquely_merge_multi_dimentional_list_of_lists(previously_visited_operon_list))\n",
      "        for an_operon in set(input_dictionary.keys()) - set(uniquely_merge_multi_dimentional_list_of_lists(previously_visited_operon_list)):\n",
      "            print \"\\t\\t build_direct_sbider_path: OPERON:\", an_operon\n",
      "            \n",
      "            if an_operon not in memory_operon:\n",
      "                activation_requirement = input_dictionary[an_operon]\n",
      "                print \"\\t\\t build_direct_sbider_path: Avtivation Requirement:\", activation_requirement\n",
      "\n",
      "                if match_any_list(activation_requirement, just_previously_produced_species_list) == True:\n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    print \"\\t\\t\\t build_direct_sbider_path: Activation!!! of\", an_operon\n",
      "\n",
      "                    visited_operon_list = previously_visited_operon_list + [an_operon]\n",
      "\n",
      "                    just_produced_species = output_dictionary[an_operon]\n",
      "                    just_produced_unique_species = uniquely_merge_multi_dimentional_list_of_lists(just_produced_species)\n",
      "\n",
      "                    if match_any_list(just_produced_species, output_species_list):\n",
      "                        print \"\\t\\t\\t\\t build_direct_sbider_path: Match!!!!!!!!!\"\n",
      "                        \n",
      "                        if indirect_flag == False:\n",
      "                            print \"\\t\\t\\t\\t build_direct_sbider_path: BEFORE ope:\", final_operon_path_list\n",
      "                            final_operon_path_list.append(visited_operon_list)\n",
      "                            print \"\\t\\t\\t\\t build_direct_sbider_path: AFTER ope:\", final_operon_path_list\n",
      "                    else:\n",
      "                        path_queue.append((visited_operon_list,just_produced_unique_species))\n",
      "                        memory_operon.append(an_operon)\n",
      "                        memory_operon = remove_duplicates_within_list(memory_operon)                        \n",
      "                        memory_species.extend(just_produced_unique_species)\n",
      "                        memory_species = remove_duplicates_within_list(memory_species)\n",
      "\n",
      "                    activated_paths.append([[an_operon],just_produced_unique_species])                        \n",
      "                   \n",
      "        print \"\\t build_direct_sbider_path: exiting while loop for queue\"\n",
      "        print\n",
      "    \n",
      "    if indirect_flag == True:\n",
      "        print \"build_direct_sbider_path: ENTERING--- build_indirect_sbider_path\"\n",
      "        final_operon_path_list = build_indirect_sbider_path(input_dictionary,\n",
      "                                   output_dictionary,\n",
      "                                   input_species_list,\n",
      "                                   output_species_list,\n",
      "                                   path_queue,\n",
      "                                   final_operon_path_list,\n",
      "                                   memory_operon,\n",
      "                                   memory_species,\n",
      "                                   activated_paths)\n",
      "        print \"build_direct_sbider_path: ---RETURNING build_indirect_sbider_path\"\n",
      "        print\n",
      "        \n",
      "    return final_operon_path_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sbider_path(inp_dic,\n",
      "                    outp_dic,\n",
      "                    inp_spe,\n",
      "                    outp_spe,\n",
      "                    indirect_flag=False):\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print \"~IN get_sbider_path~\"\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print\n",
      "    print\n",
      "    \n",
      "    final_ope_path = []\n",
      "    \n",
      "    path_queue = [([],inp_spe)]\n",
      "    \n",
      "    memory_ope = []\n",
      "    memory_spe = []\n",
      "    memory_spe.extend(inp_spe)\n",
      "    \n",
      "    activated_paths = []\n",
      "    \n",
      "    print \"get_sbider_path: ENTERING--- build_direct_sbider_path\"\n",
      "    build_direct_sbider_path(inp_dic,\n",
      "                             outp_dic,\n",
      "                             inp_spe,\n",
      "                             outp_spe,\n",
      "                             path_queue,\n",
      "                             final_ope_path,\n",
      "                             memory_ope,\n",
      "                             memory_spe,\n",
      "                             activated_paths,\n",
      "                             indirect_flag)\n",
      "    print \"get_sbider_path: ---RETURNING build_direct_sbider_path\"\n",
      "    print\n",
      "    \n",
      "    print \"get_sbider_path: final_ope_path: BEFORE\", final_ope_path\n",
      "    if len(final_ope_path) > 0:\n",
      "        final_ope_path = remove_duplicated_lists_within_a_list_of_lists(final_ope_path)\n",
      "    print \"get_sbider_path: final_ope_path: AFTER\", final_ope_path\n",
      "    \n",
      "    return final_ope_path, inp_spe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_path_dictionary, output_path_dictionary = make_ope_id_spe_id_dicts(cur)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main(cur, user_input):\n",
      "    logic_dictionary = parse_logic(cur, user_input)\n",
      "\n",
      "    print \"\\nlogic_dictionary:\", logic_dictionary\n",
      "\n",
      "    for input_species, output_species_list in logic_dictionary.items():\n",
      "\n",
      "        ###print type(output_species_list)\n",
      "\n",
      "        for output_species in output_species_list:\n",
      "\n",
      "            print \"Path:\",input_species,\"--->\",output_species,\"=\"\n",
      "            print type(input_species)\n",
      "            print type(output_species)\n",
      "            print \":)\", list(input_species)\n",
      "            print \":)\", output_species\n",
      "\n",
      "            operon_path_list = get_sbider_path(input_path_dictionary,\n",
      "                                                                  output_path_dictionary,\n",
      "                                                                  list(input_species),\n",
      "                                                                  output_species,\n",
      "                                                                  False)\n",
      "\n",
      "            # operon path\n",
      "            operon_path_subnetwork_list = []\n",
      "            for operon_path in operon_path_list:\n",
      "                print \"operon_path:\",operon_path\n",
      "                operon_path_subnetwork_list.extend(operon_path)\n",
      "            operon_path_subnetwork_graph = make_graph_from_path_list(operon_path_subnetwork_list)\n",
      "            draw_plot(operon_path_subnetwork_graph)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}