{
 "metadata": {
  "name": "",
  "signature": "sha256:ae3c7fcb69ce01947f10681caaf5369cca4198b198d561f216893f1b203e09d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import networkx as nx\n",
      "import itertools\n",
      "import collections\n",
      "import weakref"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class OrderedSet(object):\n",
      "    \"\"\"\n",
      "    A linked-list with a uniqueness constraint and O(1) lookups/removal.\n",
      "\n",
      "    Modification during iteration is partially supported.  If you\n",
      "    remove the just yielded element, it will go on to what was the\n",
      "    next element.  If you remove the next element, it will use the\n",
      "    new next element.  If you remove both, you get an error.\n",
      "    \"\"\"\n",
      "    def __init__(self, iterable=(), allow_move=True):\n",
      "        self._map = {}\n",
      "        self._start = _SentinalNode()\n",
      "        self._end = _SentinalNode()\n",
      "        self._start.next = self._end\n",
      "        self._end.prev = self._start\n",
      "        self._allow_move = allow_move\n",
      "        self.extend(iterable)\n",
      "\n",
      "    def __contains__(self, element):\n",
      "        return element in self._map\n",
      "\n",
      "    def __eq__(self, other):\n",
      "        raise TypeError(\"OrderedSet does not support comparisons\")\n",
      "\n",
      "    def __hash__(self):\n",
      "        raise TypeError(\"OrderedSet is not hashable\")\n",
      "\n",
      "    def __iter__(self):\n",
      "        curnode = self._start\n",
      "        nextnode = curnode.next\n",
      "\n",
      "        while True:\n",
      "            if hasattr(curnode, 'next'):\n",
      "                curnode = curnode.next\n",
      "            elif hasattr(nextnode, 'next'):\n",
      "                curnode = nextnode\n",
      "            else:\n",
      "                raise RuntimeError(\"OrderedSet modified inappropriately \"\n",
      "                    \"during iteration\")\n",
      "\n",
      "            if type(curnode) is _SentinalNode:\n",
      "                return\n",
      "\n",
      "            nextnode = curnode.next\n",
      "            yield curnode.content\n",
      "\n",
      "    def __reversed__(self):\n",
      "        curnode = self._end\n",
      "        prevnode = curnode.prev\n",
      "\n",
      "        while True:\n",
      "            if hasattr(curnode, 'prev'):\n",
      "                curnode = curnode.prev\n",
      "            elif hasattr(prevnode, 'prev'):\n",
      "                curnode = prevnode\n",
      "            else:\n",
      "                raise RuntimeError(\"OrderedSet modified inappropriately \"\n",
      "                    \"during iteration\")\n",
      "\n",
      "            if type(curnode) is _SentinalNode:\n",
      "                return\n",
      "\n",
      "            prevnode = curnode.prev\n",
      "            yield curnode.content\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self._map)\n",
      "\n",
      "    def __repr__(self):\n",
      "        return '%s(%r)' % (self.__class__.__name__, list(self))\n",
      "\n",
      "    def append(self, element):\n",
      "        \"\"\"Add an element to the right side of the OrderedSet.\"\"\"\n",
      "        self._insertatnode(self._end.prev, element)\n",
      "\n",
      "    def appendleft(self, element):\n",
      "        \"\"\"Add an element to the left side of the OrderedSet.\"\"\"\n",
      "        self._insertatnode(self._start, element)\n",
      "\n",
      "    def clear(self):\n",
      "        \"\"\"Remove all elements from the OrderedSet.\"\"\"\n",
      "        while self:\n",
      "            self.pop()\n",
      "\n",
      "    def extend(self, iterable):\n",
      "        \"\"\"Extend the right side of the OrderedSet with elements from the iterable.\"\"\"\n",
      "        for element in iterable:\n",
      "            self.append(element)\n",
      "\n",
      "    def extendleft(self, iterable):\n",
      "        \"\"\"Extend the left side of the OrderedSet with elements from the iterable.\"\"\"\n",
      "        for element in iterable:\n",
      "            self.appendleft(element)\n",
      "\n",
      "    def insertleft(self, poselement, element):\n",
      "        \"\"\"Inserts element immediately left of poselement's position.\"\"\"\n",
      "        self._insertatnode(self._map[poselement].prev, element)\n",
      "\n",
      "    def insertright(self, poselement, element):\n",
      "        \"\"\"Inserts element immediately right of poselement's position.\"\"\"\n",
      "        self._insertatnode(self._map[poselement], element)\n",
      "\n",
      "    def _insertatnode(self, node, element):\n",
      "        left = node\n",
      "        right = node.next\n",
      "        if element in self._map:\n",
      "            if self._allow_move:\n",
      "                self.remove(element)\n",
      "            else:\n",
      "                raise ValueError(\"element already exists\")\n",
      "\n",
      "        newnode = _Node()\n",
      "        newnode.content = element\n",
      "        newnode.prev = right.prev\n",
      "        newnode.next = right\n",
      "        right.prev = newnode\n",
      "        left.next = newnode\n",
      "        self._map[element] = newnode\n",
      "\n",
      "    def pop(self):\n",
      "        \"\"\"Remove and return the rightmost element.\"\"\"\n",
      "        element = self._end.prev.content\n",
      "        self.remove(element)\n",
      "        return element\n",
      "\n",
      "    def popleft(self):\n",
      "        \"\"\"Remove and return the leftmost element.\"\"\"\n",
      "        element = self._start.next.content\n",
      "        self.remove(element)\n",
      "        return element\n",
      "\n",
      "    def remove(self, element):\n",
      "        \"\"\"Remove element from the OrderedSet.\"\"\"\n",
      "        node = self._map.pop(element)\n",
      "        assert type(node) is not _SentinalNode\n",
      "        left = node.prev\n",
      "        right = node.next\n",
      "        left.next = right\n",
      "        right.prev = node.prev\n",
      "        del node.prev\n",
      "        del node.next\n",
      "\n",
      "\n",
      "class _Node(object):\n",
      "    __slots__ = '_prev', 'next', 'content', '__weakref__'\n",
      "    # A weakref is used for prev so as to avoid creating cycles.\n",
      "\n",
      "    def _prev_get(self):\n",
      "        return self._prev()\n",
      "    def _prev_set(self, value):\n",
      "        self._prev = weakref.ref(value)\n",
      "    def _prev_del(self):\n",
      "        del self._prev\n",
      "    prev = property(_prev_get, _prev_set, _prev_del)\n",
      "\n",
      "\n",
      "class _SentinalNode(_Node):\n",
      "    __slots__ = []\n",
      "\n",
      "\n",
      "__test__ = {\n",
      "    '__foo__': \"\"\"\n",
      "        >>> OrderedSet(range(10))\n",
      "        OrderedSet([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "        >>> list(reversed(OrderedSet(range(10))))\n",
      "        [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "        >>> stuff = OrderedSet()\n",
      "        >>> stuff.extendleft(range(20, 25))\n",
      "        >>> stuff.pop()\n",
      "        20\n",
      "        >>> stuff\n",
      "        OrderedSet([24, 23, 22, 21])\n",
      "        >>> stuff.insertleft(23, 99)\n",
      "        >>> stuff\n",
      "        OrderedSet([24, 99, 23, 22, 21])\n",
      "        >>> stuff.remove(21)\n",
      "        >>> stuff\n",
      "        OrderedSet([24, 99, 23, 22])\n",
      "        >>> len(stuff)\n",
      "        4\n",
      "        >>> 23 in stuff\n",
      "        True\n",
      "        >>> 44 in stuff\n",
      "        False\n",
      "\n",
      "        >>> OrderedSet([1, 2, 3, 2])\n",
      "        OrderedSet([1, 3, 2])\n",
      "        >>> OrderedSet([1, 2, 3, 2], allow_move=False)\n",
      "        Traceback (most recent call last):\n",
      "            ...\n",
      "        ValueError: element already exists\n",
      "    \"\"\",\n",
      "}\n",
      "\n",
      "\n",
      "def _test():\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    _test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_duplicates_within_list(seq):\n",
      "    seen = set()\n",
      "    seen_add = seen.add\n",
      "    return [ x for x in seq if not (x in seen or seen_add(x))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_is_type(lst, typ):\n",
      "    \"\"\"\n",
      "    Check if all elements in a list is the same specified type.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(lst) != list:\n",
      "        raise TypeError(\"list_is_type(lst, typ): lst is not a list\")\n",
      "    elif len(lst) <= 0:\n",
      "        raise ValueError(\"list_is_type(lst, typ): lst is empty\")\n",
      "    return all(isinstance(x,typ) for x in lst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_duplicated_lists_within_a_list_of_lists(list_of_lists):\n",
      "    \"\"\"\n",
      "    Removes any duplicated lists, which contain same elements in same order, within a list of lists.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        list_of_lists.sort()\n",
      "        trimmed = list(list_of_lists for list_of_lists,_ in itertools.groupby(list_of_lists))\n",
      "        return trimmed\n",
      "    else:\n",
      "        raise TypeError(\"remove_duplicated_lists_within_a_list_of_lists(list_of_lists): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uniquely_merge_list_of_lists(list_of_lists):\n",
      "    \"\"\"\n",
      "    Merge unique elements from lists within a list.\n",
      "    \n",
      "    Argument:\n",
      "        list_of_lists - a list that contains multiple lists.\n",
      "    \n",
      "    Return:\n",
      "        a new list that contains unique elements from all lists within a list of lists.\n",
      "    \"\"\"   \n",
      "    \n",
      "    if type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        remove_duplicated_lists_within_a_list_of_lists(list_of_lists)\n",
      "        merged_list = list(list_of_lists[0])\n",
      "        for a_list in list_of_lists[1::]:\n",
      "                for e in a_list:\n",
      "                    if e not in merged_list:\n",
      "                        merged_list.append(e)\n",
      "        return merged_list\n",
      "    else:\n",
      "        raise TypeError(\"uniquely_merge_list_of_lists(list_of_lists): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uniquely_merge_multi_dimentional_list_of_lists(multi_dimentional_list_of_lists):\n",
      "    final_merged_list = uniquely_merge_list_of_lists(multi_dimentional_list_of_lists)\n",
      "    print \"1\", final_merged_list\n",
      "    if type(final_merged_list) == list and len(final_merged_list) > 0 and list_is_type(final_merged_list, list) == True:\n",
      "        return uniquely_merge_multi_dimentional_list_of_lists(final_merged_list)\n",
      "    else:\n",
      "        return final_merged_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def elements_match(list_of_lists, lst):\n",
      "    return set(lst).issubset(uniquely_merge_list_of_lists(list_of_lists))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_matching_list(list_of_lists, lst):\n",
      "    \"\"\"\n",
      "    Get any list that match a specified list.\n",
      "    \"\"\"\n",
      "    \n",
      "    if type(lst) != list:\n",
      "        raise TypeError(\"get_matching_list(list_of_lists, lst): lst is not a list object\")    \n",
      "    elif type(list_of_lists) == list and len(list_of_lists) > 0 and list_is_type(list_of_lists, list) == True:\n",
      "        matching_list = []\n",
      "        for a_list in list_of_lists:\n",
      "            if all([x in lst for x in a_list]) == True:\n",
      "                matching_list.append(a_list)\n",
      "        return matching_list\n",
      "    else:\n",
      "        raise TypeError(\"get_matching_list(list_of_lists, lst): list_of_lists should be in the form: [[],[],... ]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def match_any_list(list_of_lists, lst):\n",
      "    \"\"\"\n",
      "    Check if a list matches any of lists within a list.\n",
      "    \"\"\"\n",
      "            \n",
      "    if get_matching_list(list_of_lists, lst) == []:\n",
      "        return False\n",
      "    else:\n",
      "        return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sbider_path(input_dictionary, output_dictionary,\n",
      "                    input_species_list, output_species_list):\n",
      "    path_queue = [ ([],input_species_list) ]\n",
      "    final_operon_path_list = []\n",
      "    final_species_path_list = []\n",
      "    memory_species_queue = [input_species_list]\n",
      "    memory_species = set()\n",
      "    memory_operon = set()\n",
      "    \n",
      "    sbider_path(input_dictionary, output_dictionary,\n",
      "                input_species_list, output_species_list,\n",
      "                path_queue,\n",
      "                final_operon_path_list, final_species_path_list,\n",
      "                memory_operon, memory_species,\n",
      "                memory_species_queue\n",
      "                )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sbider_path(input_dictionary, output_dictionary,\n",
      "                input_species_list, output_species_list,\n",
      "                path_queue,\n",
      "                final_operon_path_list, final_species_path_list,\n",
      "                memory_operon, memory_species,\n",
      "                memory_species_queue):\n",
      "    \"\"\"Construct path\"\"\"\n",
      "    \n",
      "    # keeps track of activated operon path, species path, and just previously produces species - to be explored\n",
      "\n",
      "    \n",
      "    print \"input_species_list:\", input_species_list\n",
      "    print \"output_species_list:\", output_species_list\n",
      "    \n",
      "    print \"#\" * 99\n",
      "    while path_queue != []:\n",
      "        \n",
      "        print \"\\n\\n\\n ######### <per pop> path_queue #########\"\n",
      "        for a_queue_pair in path_queue:\n",
      "            print \"\\t\", a_queue_pair\n",
      "            \n",
      "        print \"\\n ######### <per pop> visited_species_list_queue #########\"\n",
      "        for a_previously_visited_species_list in memory_species_queue:\n",
      "            print \"\\t\", a_previously_visited_species_list\n",
      "        \n",
      "        (previously_visited_operon_list, just_previously_produced_species_list) = path_queue.pop(0)\n",
      "        previously_visited_species_list = memory_species_queue.pop(0)\n",
      "        \n",
      "        print \"searching for operons that can be activated by just_previously_produced_species_list\", just_previously_produced_species_list, \"...\"\n",
      "        print \"operons yet to be visited:\", set(input_dictionary.keys()) - set(previously_visited_operon_list)\n",
      "        for an_operon in set(input_dictionary.keys()) - set(previously_visited_operon_list):\n",
      "\n",
      "            print \"\\n\\t\\t potential operon & its input species:\", an_operon, \" & \", input_dictionary[an_operon]\n",
      "            print \"\\t\\t (ACTIVATE?)Does species\", just_previously_produced_species_list, \"match an_operon's input species:\", input_dictionary[an_operon],\"???\"\n",
      "            if match_any_list(input_dictionary[an_operon], just_previously_produced_species_list) == True:\n",
      "\n",
      "                print \"\\n\\t\\t\\t !!!ACTIVATION!!!\"\n",
      "                print \"\\t\\t\\t <OPERON>\"\n",
      "                print \"\\t\\t\\t (<before>) previously_visited_operon_list:\", previously_visited_operon_list\n",
      "                print \"\\t\\t\\t (<change>) an_operon:\", an_operon\n",
      "                # store activated operon\n",
      "                visited_operon_list = previously_visited_operon_list + [an_operon]\n",
      "                print \"\\t\\t\\t(<after>) visited_operon_list:\", visited_operon_list\n",
      "\n",
      "                print \"\\t\\t\\t <SPECIES>\"\n",
      "                print \"\\t\\t\\t (<before>) previously_visited_species_list:\", previously_visited_species_list\n",
      "                just_produced_species_list = output_dictionary[an_operon]\n",
      "                print \"\\t\\t\\t (<change>) just produced species by\", \"operon (ope_id\", an_operon, \"):\", just_produced_species_list\n",
      "                # update visited species list with unique species produced'\n",
      "                \n",
      "                visited_species_list = previously_visited_species_list + uniquely_merge_list_of_lists(just_produced_species_list)\n",
      "                \n",
      "                # removes duplicates\n",
      "                print \"\\t\\t\\t (<after> removing dubpicates>) visited_species_list:\", visited_species_list\n",
      "                visited_species_list = remove_duplicates_within_list(visited_species_list)\n",
      "                print \"\\t\\t\\t (<after> duplicated removed) visited_species_list:\", visited_species_list\n",
      "                \n",
      "                print \"\\t\\t\\t Can\", output_species_list, \"be found in\", just_produced_species_list,\"???\"\n",
      "                # if output speices is found, include this operon and species path lists in the \n",
      "                # final operon and species paths\n",
      "                if match_any_list(just_produced_species_list, output_species_list):\n",
      "\n",
      "                    print \"\\t\\t\\t\\t !!!OUTPUT SPECIES FOUND!!! \\n\"\n",
      "\n",
      "                    # adds this path to the final operon and species path lists, which contain many correct paths\n",
      "                    final_operon_path_list.append(visited_operon_list)\n",
      "                    final_species_path_list.append(list(visited_species_list))\n",
      "\n",
      "                    print \"\\n\\t\\t\\t\\t final_operon_path_list:\", final_operon_path_list\n",
      "                    print \"\\t\\t\\t\\t final_species_path_list:\", final_species_path_list, \"\\n\"\n",
      "\n",
      "                # If output species is not found, include this operon and species path lists in path queue\n",
      "                else:\n",
      "\n",
      "                    print \"\\t\\t\\t\\t This activated operon(ope_id:\", an_operon, \") does not produce output species, but produces\", just_produced_species_list, \"and this path is to be continually explored later (appending in path_queue)\"\n",
      "                    path_queue.append( (visited_operon_list,uniquely_merge_list_of_lists(just_produced_species_list)) )\n",
      "                    memory_species_queue.append(visited_species_list)\n",
      "                    memory_species.append(visited_species_list)\n",
      "                    \n",
      "                    print \"\\n\\t\\t\\t\\t ##### <per an_operon> path_queue #####\"\n",
      "                    for a_queue_pair in path_queue:\n",
      "                        print \"\\t\\t\\t\\t\\t\", a_queue_pair\n",
      "\n",
      "                    print \"\\n\\t\\t\\t\\t ###### <per an_operon> visited_species_list_queue #####\"\n",
      "                    for a_previously_visited_species_list in memory_species_queue:\n",
      "                        print \"\\t\\t\\t\\t\\t\", a_previously_visited_species_list\n",
      "                    print \"\\n\\n\\n\"\n",
      "                \n",
      "                memory_operon.add(an_operon)\n",
      "    \n",
      "    print \"XXXXX\"\n",
      "    update_sbider_path_aggr(input_dictionary,\n",
      "                            output_dictionary,\n",
      "                            path_queue,\n",
      "                            memory_operon,\n",
      "                            memory_species,\n",
      "                            output_species_list,\n",
      "                            final_operon_path_list,\n",
      "                            final_species_path_list\n",
      "                            )\n",
      "\n",
      "    return final_operon_path_list, final_species_path_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sbider_path_aggr(input_dictionary, output_dictionary,\n",
      "                     input_species_list, output_species_list,\n",
      "                     path_queue,\n",
      "                     final_operon_path_list, final_species_path_list,\n",
      "                     memory_operon, memory_species,\n",
      "                     memory_species_queue):\n",
      "    \n",
      "    print \"path_queue:\", path_queue\n",
      "    print \"memory_operon:\", memory_operon\n",
      "    print \"memory_species:\", memory_species\n",
      "    print \"output_species_list:\", output_species_list\n",
      "    print \"final_operon_path_list:\", final_operon_path_list\n",
      "    print \"final_species_path_list:\", final_species_path_list\n",
      "    \n",
      "    combined_species_list = uniquely_merge_list_of_lists(list(memory_species))\n",
      "    print \"\\t combined_species_path_list\", combined_species_list\n",
      "    \n",
      "    while True:\n",
      "        visited_operon_list_aggr = set()\n",
      "\n",
      "        print \"\\t operons yet to be visited:\", set(input_dictionary.keys()) - visited_operon_list_aggr\n",
      "        \n",
      "        for an_operon in set(input_dictionary.keys()) - visited_operon_list_aggr:\n",
      "            print \"\\t an_operon\", an_operon\n",
      "            \n",
      "            if match_any_list(input_dictionary[an_operon], combined_species_list) == True:\n",
      "                just_produced_species_list = output_dictionary[an_operon]\n",
      "                print \"\\t\\t match\"\n",
      "                print \"\\t\\t just_produced_species_list:\", just_produced_species_list\n",
      "                \n",
      "                if match_any_list(just_produced_species_list, output_species_list):\n",
      "                    print \"\\t\\t\\t activated\"\n",
      "                    final_operon_path_list.append([an_operon])\n",
      "                    final_species_path_list.append(uniquely_merge_list_of_lists(just_produced_species_list))\n",
      "                else:\n",
      "                    if an_operon not in memory_operon:\n",
      "                        path_queue.append( ([an_operon],uniquely_merge_list_of_lists(just_produced_species_list)) )\n",
      "                        memory_operon.add(an_operon)\n",
      "                        memory_species.append(uniquely_merge_list_of_lists(just_produced_species_list))\n",
      "                        \n",
      "                        print path_queue\n",
      "            visited_operon_list_aggr.add(an_operon)\n",
      "        \n",
      "        print \"YYYYY\"\n",
      "        sbider_path(input_dictionary, output_dictionary,\n",
      "                    input_species_list, output_species_list,\n",
      "                    path_queue,\n",
      "                    final_operon_path_list, final_species_path_list,\n",
      "                    memory_operon, memory_species,\n",
      "                    memory_species_queue)\n",
      "        \n",
      "        if len(path_queue) == 0:\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_path_dictionary = {'o1':[['a']],\n",
      "                         'o2':[['a']],\n",
      "                         'o3':[['b', 'c']],\n",
      "                         'o4':[['a']],\n",
      "                         'o5':[['e']],\n",
      "                         'o6':[['f']],\n",
      "                         'o7':[['g']],\n",
      "                         'o8':[['h']],\n",
      "                         'o9':[['i']],\n",
      "                         'o10':[['j']],\n",
      "                         'o11':[['k']]\n",
      "                         }\n",
      "output_path_dictionary = {'o1':[['b']],\n",
      "                          'o2':[['c']],\n",
      "                          'o3':[['d']],\n",
      "                          'o4':[['e']],\n",
      "                          'o5':[['f']],\n",
      "                          'o6':[['g']],\n",
      "                          'o7':[['h']],\n",
      "                          'o8':[['i']],\n",
      "                          'o9':[['j']],\n",
      "                          'o10':[['k']],\n",
      "                          'o11':[['l']]\n",
      "                          }\n",
      "\n",
      "inp = ['a']\n",
      "outp = ['l']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_sbider_path(input_path_dictionary, output_path_dictionary, inp, outp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "input_species_list: ['a']\n",
        "output_species_list: ['l']\n",
        "###################################################################################################\n",
        "\n",
        "\n",
        "\n",
        " ######### <per pop> path_queue #########\n",
        "\t([], ['a'])\n",
        "\n",
        " ######### <per pop> visited_species_list_queue #########\n",
        "\t['a']\n",
        "searching for operons that can be activated by just_previously_produced_species_list ['a'] ...\n",
        "operons yet to be visited: set(['o11', 'o10', 'o9', 'o8', 'o7', 'o6', 'o5', 'o4', 'o3', 'o2', 'o1'])\n",
        "\n",
        "\t\t potential operon & its input species: o11  &  [['k']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['k']] ???\n",
        "\n",
        "\t\t potential operon & its input species: o10  &  [['j']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['j']] ???\n",
        "\n",
        "\t\t potential operon & its input species: o9  &  [['i']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['i']] ???\n",
        "\n",
        "\t\t potential operon & its input species: o8  &  [['h']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['h']] ???\n",
        "\n",
        "\t\t potential operon & its input species: o7  &  [['g']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['g']] ???\n",
        "\n",
        "\t\t potential operon & its input species: o6  &  [['f']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['f']] ???\n",
        "\n",
        "\t\t potential operon & its input species: o5  &  [['e']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['e']] ???\n",
        "\n",
        "\t\t potential operon & its input species: o4  &  [['a']]\n",
        "\t\t (ACTIVATE?)Does species ['a'] match an_operon's input species: [['a']] ???\n",
        "\n",
        "\t\t\t !!!ACTIVATION!!!\n",
        "\t\t\t <OPERON>\n",
        "\t\t\t (<before>) previously_visited_operon_list: []\n",
        "\t\t\t (<change>) an_operon: o4\n",
        "\t\t\t(<after>) visited_operon_list: ['o4']\n",
        "\t\t\t <SPECIES>\n",
        "\t\t\t (<before>) previously_visited_species_list: ['a']\n",
        "\t\t\t (<change>) just produced species by operon (ope_id o4 ): [['e']]\n",
        "\t\t\t (<after> removing dubpicates>) visited_species_list: ['a', 'e']\n",
        "\t\t\t (<after> duplicated removed) visited_species_list: ['a', 'e']\n",
        "\t\t\t Can ['l'] be found in [['e']] ???\n",
        "\t\t\t\t This activated operon(ope_id: o4 ) does not produce output species, but produces [['e']] and this path is to be continually explored later (appending in path_queue)\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "unhashable type: 'list'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-94-a184b3ad28b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_sbider_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-93-d70df36dc2c9>\u001b[0m in \u001b[0;36mget_sbider_path\u001b[0;34m(input_dictionary, output_dictionary, input_species_list, output_species_list)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mfinal_operon_path_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_species_path_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mmemory_operon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_species\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mmemory_species_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 )\n",
        "\u001b[0;32m<ipython-input-92-1ddb740ba5d7>\u001b[0m in \u001b[0;36msbider_path\u001b[0;34m(input_dictionary, output_dictionary, input_species_list, output_species_list, path_queue, final_operon_path_list, final_species_path_list, memory_operon, memory_species, memory_species_queue)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mpath_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvisited_operon_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muniquely_merge_list_of_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjust_produced_species_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mmemory_species_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisited_species_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0mmemory_species\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisited_species_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\n\\t\\t\\t\\t ##### <per an_operon> path_queue #####\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}